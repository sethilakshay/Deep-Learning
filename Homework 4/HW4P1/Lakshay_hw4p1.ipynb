{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW4P1: Language Modelling\n",
        "\n",
        "Welcome to the final part 1 hw of this course. This is the only part 1 in which you have PyTorch training (Yay). You will be working on training language models and evaluating them on the task of prediction and generation.<br>\n",
        "Note: A major change which we have made this semester is that we have made the model which you will be coding in this HW very similar to the Speller module from HW4P2."
      ],
      "metadata": {
        "id": "PSLkT0qL3jgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get modules and datasets"
      ],
      "metadata": {
        "id": "EB2bOV3bzYLR",
        "cell_id": "95e48c7693e34a389da49dcb6e448e0c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchsummaryX\n",
        "# !pip install pytorch-nlp"
      ],
      "metadata": {
        "id": "r4_-qG9rSULt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Import drive if you are using Colab\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "RnrUvEIC5i5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "pUO_VvnjmJQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvf /content/HW4/handout.tar -C /content/HW4/"
      ],
      "metadata": {
        "id": "8XfItCImbtuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/HW4/handout/\") # TODO: Add path to handout/"
      ],
      "metadata": {
        "id": "QZNwme4320LW",
        "cell_id": "03bf3bd639a048f098d5febc42e2baff",
        "source_hash": "b7876178",
        "execution_start": 1679856365820,
        "execution_millis": 4,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKBYTu0knwn_",
        "outputId": "9696ca3b-ad43-42b9-f975-3d523bc1ee40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.8/dist-packages/IPython/extensions', '/root/.ipython', '/content/HW4/handout/']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "\n",
        "import os\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import torchsummaryX\n",
        "import math\n",
        "from torchnlp.nn import LockedDropout\n",
        "\n",
        "# Importing necessary modules from hw4\n",
        "from hw4.tests_hw4 import test_prediction, test_generation\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device: \", DEVICE)"
      ],
      "metadata": {
        "id": "oxiZ42B4SwQ-",
        "tags": [],
        "cell_id": "b48a9e95f26c4d2e89d95b1b311cedd5",
        "execution": {
          "iopub.status.busy": "2022-08-10T14:02:09.987693Z",
          "iopub.status.idle": "2022-08-10T14:02:12.872562Z",
          "iopub.execute_input": "2022-08-10T14:02:09.992480Z",
          "shell.execute_reply": "2022-08-10T14:02:12.870819Z",
          "shell.execute_reply.started": "2022-08-10T14:02:09.991351Z"
        },
        "source_hash": "ec149d26",
        "execution_start": 1679856365830,
        "execution_millis": 2669,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f0fe13-b1a1-43d3-bac8-babf57fe7161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/HW4/handout"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIEXiRgC_XrZ",
        "outputId": "d3e02684-7655-4c8a-9359-ca6fdf7c3042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HW4/handout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets"
      ],
      "metadata": {
        "id": "u-R794-0zc9V",
        "cell_id": "a4ff875589ee46da8f749a7e5088a3ef",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the vocabulary. Try printing and see\n",
        "VOCAB       = np.load('dataset/vocab.npy')\n",
        "\n",
        "# We have also included <sos> and <eos> in the vocabulary for you\n",
        "# However in real life, you include it explicitly if not provided\n",
        "SOS_TOKEN   = np.where(VOCAB == '<sos>')[0][0]\n",
        "EOS_TOKEN   = np.where(VOCAB == '<eos>')[0][0]\n",
        "NUM_WORDS   = len(VOCAB) - 2 # Actual number of words in vocabulary\n",
        "\n",
        "print(\"Vocab length: \", len(VOCAB))\n",
        "print(VOCAB)\n",
        "print(''.join(VOCAB[:20]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU4e_6l0Whda",
        "outputId": "ea4a68b7-1c42-4824-b349-dfdd25d1d6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length:  33280\n",
            "['!' '\"' '#' ... '～' '<sos>' '<eos>']\n",
            "!\"#$%&''Addario'Africaine'Andrade'Automobile'Brien'Carmel'Connell'Connor'Cruz'Day'Dell'Donnell'Italia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loding the training dataset. Refer to write up section 2 to understand the structure\n",
        "dataset     = np.load('dataset/wiki.train.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "LA7SapmyXHr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))\n",
        "print(len(dataset[0]))\n",
        "print(dataset[0])\n",
        "print(type(dataset[0]))\n",
        "print(\"\\n\")\n",
        "\n",
        "## By default no blank characters\n",
        "print(' '.join([VOCAB[i] for i in dataset[0]]))\n",
        "print(' '.join([VOCAB[i] for i in dataset[1]]))\n",
        "print(' '.join([VOCAB[i] for i in dataset[2]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRN8cwAJMVCU",
        "outputId": "5a5cc8e1-a519-427e-8dda-ee864a990261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "579\n",
            "3803\n",
            "[ 1420 13859  3714 ...   813    79  1417]\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "= Valkyria Chronicles III = <eol> Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . <eol> The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . <eol> It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . <eol> = = Gameplay = = <eol> As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through <unk> text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main <unk> , although they take a very minor role . <eol> The game 's battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters ' turns . Each character has a field and distance of movement limited by their Action <unk> . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant <unk> to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special <unk> that grant them temporary <unk> on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without <unk> his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become <unk> , while Imca can target multiple enemy units with her heavy weapon . <eol> Troops are divided into five classes : Scouts , <unk> , Engineers , <unk> and Armored Soldier . <unk> can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games ' method of distributing to different unit types . <eol> = = Plot = = <eol> The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign <unk> , and military offenders whose real names are erased from the records and <unk> officially referred to by numbers . <unk> by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task , exemplified by their motto , <unk> <unk> , meaning \" Always Ready . \" The three main characters are <unk> Kurt Irving , an army officer falsely accused of treason who wishes to redeem himself ; Ace <unk> Imca , a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and <unk> Riela <unk> , a seemingly <unk> young woman who is unknowingly a descendant of the Valkyria . Together with their fellow squad members , these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven , consisting of mostly Darcsen soldiers . <eol> As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible <unk> in order to send them on missions that would otherwise make Gallia lose face in the war . While at times this works to their advantage , such as a successful incursion into Imperial territory , other orders cause certain members of the 422nd great distress . One such member , <unk> , becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven , attached to the ideal of Darcsen independence proposed by their leader , Dahau . At the same time , elements within Gallian Army Command move to erase the Nameless in order to protect their own interests . <unk> by both allies and enemies , and combined with the presence of a traitor within their ranks , the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort . This continues until the Nameless 's commanding officer , Ramsey Crowe , who had been kept under house arrest , is escorted to the capital city of <unk> in order to present evidence <unk> the weary soldiers and expose the real traitor , the Gallian General that had accused Kurt of Treason . <eol> <unk> due to these events , and partly due to the major losses in manpower Gallia suffers towards the end of the war with the Empire , the Nameless are offered a formal position as a squad in the Gallian Army rather than serve as an anonymous shadow force . This is short @-@ lived , however , as following Maximilian 's defeat , Dahau and Calamity Raven move to activate an ancient <unk> super weapon within the Empire , kept secret by their benefactor . Without the support of Maximilian or the chance to prove themselves in the war with Gallia , it is Dahau 's last <unk> card in creating a new Darcsen nation . As an armed Gallian force invading the Empire just following the two nations ' cease @-@ fire would certainly wreck their newfound peace , Kurt decides to once again make his squad the Nameless , asking Crowe to list himself and all under his command as killed @-@ in @-@ action . Now owing allegiance to none other than themselves , the 422nd confronts Dahau and destroys the <unk> weapon . Each member then goes their separate ways in order to begin their lives <unk> . <eol> = = Development = = <eol> Concept work for Valkyria Chronicles III began after development finished on Valkyria Chronicles II in early 2010 , with full development beginning shortly after this . The director of Valkyria Chronicles II , Takeshi Ozawa , returned to that role for Valkyria Chronicles III . Development work took approximately one year . After the release of Valkyria Chronicles II , the staff took a look at both the popular response for the game and what they wanted to do next for the series . Like its predecessor , Valkyria Chronicles III was developed for PlayStation Portable : this was due to the team wanting to refine the mechanics created for Valkyria Chronicles II , and they had not come up with the \" revolutionary \" idea that would warrant a new entry for the PlayStation 3 . Speaking in an interview , it was stated that the development team considered Valkyria Chronicles III to be the series ' first true sequel : while Valkyria Chronicles II had required a large amount of trial and error during development due to the platform move , the third game gave them a chance to improve upon the best parts of Valkyria Chronicles II due to being on the same platform . In addition to Sega staff from the previous games , development work was also handled by <unk> The original scenario was written <unk> <unk> , while the script was written by Hiroyuki <unk> , <unk> <unk> , <unk> <unk> , <unk> <unk> and <unk> <unk> . Its story was darker and more somber than that of its predecessor . <eol> The majority of material created for previous games , such as the <unk> system and the design of maps , was carried over . Alongside this , improvements were made to the game 's graphics and some elements were expanded , such as map layouts , mission structure , and the number of playable units per mission . A part of this upgrade involved creating unique <unk> models for each character 's body . In order to achieve this , the cooperative elements incorporated into the second game were removed , as they took up a large portion of memory space needed for the improvements . They also adjusted the difficulty settings and ease of play so they could appeal to new players while retaining the essential components of the series ' gameplay . The newer systems were decided upon early in development . The character designs were done by <unk> Honjou , who had worked on the previous Valkyria Chronicles games . When creating the Nameless Squad , Honjou was faced with the same problem he had had during the first game : the military uniforms essentially destroyed character individuality , despite him needing to create unique characters the player could identify while maintaining a sense of reality within the Valkyria Chronicles world . The main color of the Nameless was black . As with the previous Valkyria games , Valkyria Chronicles III used the <unk> graphics engine . The anime opening was produced by Production I.G. <eol> = = = Music = = = <eol> The music was composed by Hitoshi Sakimoto , who had also worked on the previous Valkyria Chronicles games . When he originally heard about the project , he thought it would be a light tone similar to other Valkyria Chronicles games , but found the themes much darker than expected . An early theme he designed around his original vision of the project was rejected . He <unk> the main theme about seven times through the music production due to this need to <unk> the game . The main theme was initially recorded using orchestra , then Sakimoto removed elements such as the guitar and bass , then adjusted the theme using a synthesizer before <unk> segments such as the guitar piece on their own before incorporating them into the theme . The rejected main theme was used as a hopeful tune that played during the game 's ending . The battle themes were designed around the concept of a \" modern battle \" divorced from a fantasy scenario by using modern musical instruments , constructed to create a sense of <unk> . While Sakimoto was most used to working with synthesized music , he felt that he needed to incorporate live instruments such as orchestra and guitar . The guitar was played by <unk> <unk> , who also arranged several of the later tracks . The game 's opening theme song , \" If You Wish for ... \" ( <unk> , <unk> Kimi <unk> <unk> <unk> ) , was sung by Japanese singer May 'n . Its theme was the reason soldiers fought , in particular their wish to protect what was precious to them rather than a sense of responsibility or duty . Its lyrics were written by <unk> <unk> , who had worked on May 'n on previous singles . <eol> = = = Release = = = <eol> In September 2010 , a teaser website was revealed by Sega , hinting at a new Valkyria Chronicles game . In its September issue , Famitsu listed that Senjō no Valkyria 3 would be arriving on the PlayStation Portable . Its first public appearance was at the 2010 Tokyo Game Show ( TGS ) , where a demo was made available for journalists and attendees . During the publicity , story details were kept <unk> so as not to <unk> too much for potential players , along with some of its content still being in flux at the time of its reveal . To promote the game and detail the story leading into the game 's events , an episodic Flash visual novel written by <unk> began release in January 2011 . The game was released January 27 , 2011 . During an interview , the development team said that the game had the capacity for downloadable content ( DLC ) , but that no plans were finalized . Multiple DLC maps , featuring additional missions and <unk> characters , were released between February and April 2011 . An expanded edition of the game , Valkyria Chronicles III Extra Edition , released on November 23 , 2011 . <unk> and sold at a lower price than the original , Extra Edition game with seven additional episodes : three new , three chosen by staff from the game 's DLC , and one made available as a pre @-@ order bonus . People who also owned the original game could transfer their save data between versions . <eol> Unlike its two predecessors , Valkyria Chronicles III was not released in the west . According to Sega , this was due to poor sales of Valkyria Chronicles II and the general unpopularity of the PSP in the west . An unofficial fan translation patch began development in February 2012 : players with a copy of Valkyria Chronicles III could download and apply the patch , which translated the game 's text into English . <unk> with the Extra Edition , the patch was released in January 2014 . <eol> = = Reception = = <eol> On its day of release in Japan , Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts . By early February , the game sold 102 @,@ <unk> units , coming in second overall to The Last Story for the Wii . By the end of the year , the game had sold just over 152 @,@ 500 units . <eol> Famitsu enjoyed the story , and were particularly pleased with the improvements to gameplay . Japanese gaming site Game Watch <unk> , despite negatively noting its pacing and elements recycled from previous games , was generally positive about its story and characters , and found its gameplay entertaining despite off @-@ putting difficulty spikes . <unk> writer <unk> <unk> , in a \" Play Test \" article based on the game 's <unk> demo , felt that Valkyria Chronicles III provided a \" profound feeling of closure \" for the Valkyria Chronicles series . He praised its gameplay despite annoying limitations to aspects such as special abilities , and positively noted its shift in story to a tone similar to the first game . <eol> PlayStation Official Magazine - UK praised the story 's <unk> of Gallia 's moral standing , art style , and most points about its gameplay , positively noting the latter for both its continued quality and the tweaks to balance and content . Its one major criticism were multiple difficulty spikes , something that had affected the previous games . Heath Hindman of gaming website PlayStation <unk> praised the addition of non @-@ linear elements and improvements or removal of mechanics from Valkyria Chronicles II in addition to praising the returning gameplay style of previous games . He also positively noted the story 's serious tone . Points criticized in the review were recycled elements , awkward cutscenes that seemed to include all characters in a scene for no good reason , pacing issues , and occasional problems with the game 's AI . <eol> In a preview of the TGS demo , Ryan Geddes of IGN was left excited as to where the game would go after completing the demo , along with enjoying the improved visuals over Valkyria Chronicles II . Kotaku 's Richard <unk> was highly positive about the game , citing is story as a return to form after Valkyria Chronicles II and its gameplay being the best in the series . His main criticisms were its length and gameplay repetition , along with expressing regret that it would not be localized . <eol> = = Legacy = = <eol> Kurt and Riela were featured in the Nintendo 3DS crossover Project X Zone , representing the Valkyria series . Media.Vision would return to the series to develop Valkyria : Azure Revolution , with Ozawa returning as director . Azure Revolution is a role @-@ playing video game for the PlayStation 4 that forms the beginning of a new series within the Valkyria franchise . <eol> = = = Adaptations = = = <eol> Valkyria Chronicles 3 was adapted into a two @-@ episode original video animation series in the same year of its release . <unk> Senjō no Valkyria 3 : <unk> <unk> no <unk> ( <unk> <unk> , lit . Valkyria of the Battlefield 3 : The <unk> Taken for <unk> 's Sake ) , it was originally released through PlayStation Network and <unk> between April and May 2011 . The initially @-@ planned release and availability period needed to be extended due to a stoppage to <unk> during the early summer of that year . It later released for DVD on June 29 and August 31 , 2011 , with separate \" Black \" and \" Blue \" editions being available for purchase . The anime is set during the latter half of Valkyria Chronicles III , detailing a mission by the Nameless against their Imperial rivals Calamity Raven . The anime was first announced in November 2010 . It was developed by A @-@ 1 Pictures , produced by Shinji <unk> , directed by <unk> <unk> , and written by Hiroshi <unk> . Sakimoto 's music for the game was used in the anime . <eol> The anime 's title was inspired by the principle purpose of the Nameless : to suffer in battle for the goals of others . A <unk> attached to the project during development was \" The Road to <unk> \" , which referenced the <unk> Tank Museum in Moscow . The game 's main theme was how the characters regained their sense of self when stripped of their names and identities , along with general themes focused on war and its consequences . While making the anime , the production team were told by Sega to make it as realistic as possible , with the consequence that the team did extensive research into aspects such as what happened when vehicles like tanks were overturned or damaged . Due to it being along the same timeline as the original game and its television anime adaptation , the cast of Valkyria Chronicles could make appearances , which pleased the team . The opening theme , \" <unk> ( Light ) <unk> \" ( <unk> @-@ <unk> ) , was sung by Japanese singer <unk> . The ending theme , \" <unk> the Flowers of Light Will Bloom \" ( <unk> , <unk> <unk> <unk> no <unk> ) , was sung by <unk> <unk> . Both songs ' lyrics were written by their respective artists . <eol> Two manga adaptations were produced , following each of the game 's main female protagonists Imca and Riela . They were Senjō no Valkyria 3 : <unk> <unk> <unk> no <unk> ( 戦場のヴァルキュリア3 <unk> , lit . Valkyria of the Battlefield 3 : The Flower of the Nameless Oath ) , illustrated by <unk> <unk> and eventually released in two volumes after being serialized in Dengeki <unk> between 2011 and 2012 ; and Senjō no Valkyria 3 : <unk> <unk> no <unk> <unk> ( 戦場のヴァルキュリア3 <unk> , lit . Valkyria of the Battlefield 3 <unk> <unk> of the Crimson Fate ) , illustrated by <unk> <unk> and eventually released in a single volume by Kadokawa Shoten in 2012 . <eol>\n",
            "= Tower Building of the Little Rock Arsenal = <eol> The Tower Building of the Little Rock Arsenal , also known as U.S. Arsenal Building , is a building located in MacArthur Park in downtown Little Rock , Arkansas . Built in 1840 , it was part of Little Rock 's first military installation . Since its decommissioning , The Tower Building has housed two museums . It was home to the Arkansas Museum of Natural History and Antiquities from 1942 to 1997 and the MacArthur Museum of Arkansas Military History since 2001 . It has also been the headquarters of the Little Rock Æsthetic Club since 1894 . <eol> The building receives its name from its distinct octagonal tower . Besides being the last remaining structure of the original Little Rock Arsenal and one of the oldest buildings in central Arkansas , it was also the birthplace of General Douglas MacArthur , who became the supreme commander of US forces in the South Pacific during World War II . It was also the starting place of the Camden Expedition . In 2011 it was named as one of the top 10 attractions in the state of Arkansas by <unk> <eol> = = Construction = = <eol> The arsenal was constructed at the request of Governor James <unk> Conway in response to the perceived dangers of frontier life and fears of the many Native Americans who were passing through the state on their way to the newly established Oklahoma Territory . Thirty @-@ six acres were appropriated on the outskirts of Little Rock by Major Robert B. Lee of the U.S. Army . The land had been previously used as a racetrack by the local jockey club . John <unk> Walker , a builder for the Federal Government , supervised the construction . Originally $ 14 @,@ 000 was allocated for the construction of the arsenal , but proved inadequate . The budget was later increased to $ 30 @,@ 000 . Work began on the Tower Building in 1840 , and it was the first permanent structure of the arsenal to be built . Being originally constructed to store ammunition , the building was designed with 3 @-@ foot @-@ thick ( 0 @.@ 91 m ) exterior walls . The original plans called for it to be built of stone , however , masonry was used instead . The Arkansas Gazette referred to the structure as \" A splendid specimen of masonry \" . <eol> = = Civil War = = <eol> For several years the arsenal , which was owned by the federal government , served as a simple arms depot and was staffed with only a handful of soldiers . But in November 1860 , with the American Civil War on the horizon , a company of the Second United States Artillery , consisting of sixty @-@ five men , was transferred to Little Rock under the command of Captain James Totten . On January 15 , 1861 , the state legislature decided to hold a referendum to determine if a state convention should be held to consider the issue of <unk> and to elect delegates to such a convention . It was planned for February 18 ; however , events at the arsenal , would not wait . On January 28 , then Governor Henry Massey Rector informed Captain Totten that he and his soldiers would be \" permitted to remain in the possession of the Federal officers until the State , by authority of the people , shall have determined to <unk> their connection with the General Government , \" Totten responded to this by telling the Governor that his orders came from the United States Government and began a desperate but ultimately futile dispatch of letters and <unk> asking for reinforcements , although rumors were widely spread that they were already coming . The first telegraph wire to span between Little Rock and Memphis had recently been completed . Local attorney John M Harrel was asked to compose the first telegraph dispatched from Arkansas 's capital . In his message , Harrel reported unconfirmed rumors that more federal troops had been sent to reinforce the Little Rock Arsenal . <eol> The United States troops at the outposts of the western frontier of the state and in the Indian nation have all been recalled from winter quarters to reinforce the garrison at Fort Smith . The garrison at Fort Smith had been previously transferred to the United States Arsenal in this city ( Little Rock ) . The arsenal is one of the richest <unk> of military stores in the United States and is supposed to be the ultimate destination of the <unk> [ sic ] ordered from the frontier . <eol> <unk> M Harrel <unk> , January 31 , 1861 <eol> The item was intended simply as a piece of news , but telegraph lines quickly spread the news throughout the state , <unk> procession sentiment . The rumor was interpreted by some <unk> as a call from the governor to assemble to help expel the federal troops from the arsenal . By February 5 , six militia units , consisting of 1 @,@ 000 men , with a guarantee that the numbers could be increased to 5 @,@ 000 if the situations deemed it necessary , had assembled in Little Rock . Governor Rector vehemently denied ordering the troops to assemble or giving any order at all in connection with the troops . Faced with the fact that the military had assembled believing they were following his orders and the consensus of the citizens of Little Rock against any armed conflict between the civilian army and federal troops , Governor Rector was forced to take control of the situation . On February 6 , he sent a formal demand for surrender of the arsenal to Captain Totten , <eol> This movement is prompted by the feeling that <unk> the citizens of this State that in the present emergency the arms and munitions of war in the Arsenal should be under the control of the State authorities , in order to their security . This movement , although not authorized by me , has assumed such an aspect that it becomes my duty , as the executive of this <unk> , to <unk> my official authority to prevent a collision between the people of the State and the Federal troops under your command . I therefore demand in the name of the State the delivery of the possession of the Arsenal and munitions of war under your charge to the State authorities , to be held subject to the action of the convention to be held on the 4th of March next . <eol> Perhaps because Abraham Lincoln had not yet been inaugurated as President , Captain Totten received no instructions from his superiors and was forced to withdraw his troops . He agreed to surrender the arsenal as long as the governor agreed to three provisions : <eol> The governor would take possession of the arsenal in the name of the United States . <eol> The soldiers would be allowed safe passage in any direction carrying any personal and public property besides munitions of war . <eol> The soldiers would be allowed to march away as men leaving under orders , not as conquered and surrendering soldiers . <eol> On the morning of February 8 , 1861 , Rector and Totten signed an agreement placing the arsenal in the hands of state officials . That afternoon , the citizen militia marched to the arsenal with Governor Rector at its head . All of the federal troops had left at this point , except Totten who had stayed behind to listen to the Governor 's speech and to hand the arsenal over in person . <eol> The Little Rock Arsenal was classified in 1860 as an \" arsenal of deposit , \" meaning that it was simply a warehouse for the storage of weapons intended for the use of the state militia in times of crisis . Thus there were no substantial operations for ordnance fabrication or repairs , nor for the manufacture of cartridges at the time the Arsenal fell into State hands . Most of these operations were started from scratch through the efforts of the Arkansas Military Board . <eol> Inside the Little Rock Arsenal after its seizure in February , 1861 , the Confederates <unk> some 10 @,@ 247 weapons , 250 @,@ 000 musket cartridges , and 520 @,@ 000 percussion caps , as well as the four bronze cannon of Totten 's battery . Long arms in the Arsenal 's inventory consisted of : <eol> M1822 .69 cal ( flintlock ) 5 @,@ 625 <eol> M1822 .69 cal ( percussion @-@ converted ) 53 <eol> <unk> .69 cal smoothbore ( percussion ) 357 <eol> <unk> <unk> cal rifle @-@ <unk> 900 <eol> <unk> common rifles 125 <eol> <unk> rifle ( \" Mississippi Rifle \" ) 54 <eol> <unk> <unk> 2 <eol> Hall 's <unk> 267 <eol> Hall 's rifles ( flintlock ) 2 @,@ 864 <eol> Total 10 @,@ 247 <eol> Of this number , approximately <unk> weapons were <unk> , or ready @-@ for @-@ issue . Note there were only 1 @,@ 364 percussion weapons available . <unk> of the weapons found in the Arsenal is somewhat sketchy , but from various records it can be surmised that the 5th , 6th , 7th , and 8th Arkansas Infantry Regiments , mustered in June , 1861 , were issued <unk> / M1822 .69 caliber <unk> . The 9th and 10th Arkansas , four companies of Kelly 's 9th Arkansas Battalion , and the 3rd Arkansas Cavalry Regiment were issued flintlock Hall 's Rifles . The units comprising the infantry force of Van Dorn 's Army of the West were the 1st and 2nd Arkansas Mounted Rifles were also armed with M1822 <unk> from the Little Rock Arsenal . By the time the 11th and 12th Arkansas Infantry Regiments mustered in at Little Rock , the supply of arms had been almost completely exhausted , and only old \" <unk> \" weapons were left . <eol> Most of the equipment , arms , and machinery at the Little Rock Arsenal was removed to east of the Mississippi River by order of <unk> Gen. Earl Van Dorn in April and May 1862 , and accountability for it is lost at that point . By all appearances , the equipment was sent down the river to Napoleon , Arkansas , and from there to Jackson Mississippi , where it was probably destroyed during the <unk> campaign in the early summer of 1863 . <eol> Major General Thomas C. Hindman , sent to command the district of Arkansas in May , 1862 , found the state nearly destitute of military material . Hindman established another armory at Arkadelphia , and revived the Little Rock Arsenal as a collection point and depot for <unk> and ammunition manufacture for small arms . Hindman recorded : <eol> \" Machinery was made for manufacturing percussion caps and small arms , and both were turned out in small quantity , but of excellent quality . Lead mines were opened and worked , and a chemical laboratory was established and successfully operated in aid of the Ordnance Department and in the manufacture of <unk> , <unk> oil , spirits of <unk> , the various <unk> of iron , and other valuable medicines . Most of these works were located at or near Arkadelphia on the <unk> River , 75 miles south from Little Rock . The tools , machinery , and the material were gathered <unk> or else made by hand labor . Nothing of this sort had been before attempted on Government account in Arkansas to my knowledge , except for the manufacture of small arms , the machinery for which was taken away by General Van Dorn and there was neither capital nor sufficient enterprise among the citizens to engage in such undertakings <unk> A further supply , along with lead and caps , was procured from the citizens of Little Rock and vicinity by donation , purchases , and <unk> . <eol> This ammunition , and that which I brought with me , was rapidly prepared for use at the Laboratory established at the Little Rock Arsenal for that purpose . As illustrating as the <unk> <unk> of material in the country , the fact may be stated that it was found necessary to use public documents of the State Library for cartridge paper . <unk> were employed or conscripted , tools purchased or impressed , and the repair of the damaged guns I brought with me and about an equal number found at Little Rock commenced at once . But , after inspecting the work and observing the spirit of the men I decided that a garrison 500 strong could hold out against Fitch and that I would lead the remainder - about 1500 - to <unk> 'l <unk> as soon as shotguns and rifles could be obtained from Little Rock instead of <unk> and lances , with which most of them were armed . Two days <unk> before the change could be effected . \" <eol> The Confederate ordnance establishment at Little Rock was reactivated in August , 1862 . Looking around for a suitable person to head this activity , General Hindman turned to the Confederate Navy and borrowed Lieutenant John W. Dunnington . Lt. Dunnington was the commander of the gunboat <unk> <unk> , which had been brought to Little Rock in hopes of converting it to an ironclad . Dunnington was selected to head the ordnance works at Little Rock , and although he continued to draw his pay from the Confederate Navy Department , he was placed in charge of all Confederate ordnance activities ( which included artillery functions ) there with the rank of lieutenant colonel . <eol> Lt. Col. Dunnington 's \" <unk> for the month of August , 1862 , at Little Rock Arsenal , <unk> , \" are found in Vol . 149 , Chapter IV of the \" <unk> Rebel Ordnance Records , \" and are most enlightening as to the scope of Confederate ordnance activities at Little Rock during this crucial time . According to Dunnington , \" When I assumed command at this Post , all material had been removed to Arkadelphia . There were no persons employed . No shops were open for repair of arms or for <unk> ammunition . Material , tools , etc . , had to be procured as well as the employment of laborers . Work commenced the last part of the month . \" <eol> The military force at Little Rock under Dunnington 's command consisted of four officers : himself , Major John B. <unk> , Captain <unk> Green , and 2nd Lt. <unk> Murphy . In addition to these , he had 20 enlisted men and a civilian force composed of a <unk> , 2 clerks , 3 <unk> for repairing small arms , a <unk> , 26 laborers in the ammunition laboratory , and a carpenter for making packing boxes . <eol> During the month of August , 1862 , the following work was performed : \" <unk> : one pair of musket bullet moulds ; 10 @,@ 000 buck & ball shot cartridges ; repaired : 750 <unk> , shotguns , and rifles ; received and repaired : ordnance stores and <unk> ; performed : guard , office , and police duties ; inspected : <unk> at Camden and Arkadelphia . \" <eol> Lt. Col. Dunnington continued to build up his works at Little Rock until November 1862 , when Captain Sanford C. Faulkner ( composer of The Arkansas Traveler ) was placed in charge of the Arsenal . Dunnington presumably returned to his naval duties and the <unk> . <eol> A \" Summary of the Work <unk> for November , 1862 , Little Rock Arsenal \" shows : <unk> : <eol> 75 @,@ 000 buck & ball cartridges - percussion <eol> 14 @,@ 000 buck & ball cartridges - flint <eol> 275 paper <unk> <eol> 117 rounds , 6 @-@ pounder <unk> shot <eol> 130 rounds , 6 @-@ pounder ball shot <eol> 96 ammunition packing boxes <eol> <unk> : <eol> 2 @,@ 236 shotguns and rifles ( repaired mostly for troops in service ) <eol> 23 pistols ( repaired mostly for troops in service ) <eol> <unk> & <unk> : <eol> <unk> packages of ordnance and ordnance stores received and mostly issued to troops in service . <eol> <unk> and painted : <eol> 4 gun carriages <eol> Performed : <eol> Guard , office , and police duties . <eol> Perhaps the most <unk> points of the above \" Summary of Work \" and those for following months are that the standard ammunition made was . \" buck & ball \" , indicating that the .69 caliber <unk> and shotguns remained the predominant caliber weapon in use , and of this , nearly one sixth or more of all small arms ammunition was still for flintlock weapons , indicating that no less than a sixth of the Confederate troops in this vicinity were still armed with obsolete flintlock weapons . <eol> The \" <unk> of Work done at Little Rock Arsenal , <unk> \" continue at about the same pace and scale from August 1862 until August 1863 . <unk> to the \" Summary \" for August , 1863 is the ominous <unk> , \" During the last week in the month , nearly all stores at the Arsenal have been packed and sent to Arkadelphia , in obedience to orders from Chief of Ordnance , District of Arkansas . \" This then marks the beginning of the evacuation of ordnance activities from Little Rock , with the city being surrendered to the advancing Federal troops of Frederick Steele 's Arkansas Expedition on September 11 , 1863 . <eol> In 1864 , after Little Rock fell to the Union Army and the arsenal had been recaptured , General <unk> Steele marched 8 @,@ 500 troops from the arsenal beginning the Camden Expedition . <eol> The arsenal was briefly seized once more by Joseph Brooks loyalists during the Brooks @-@ <unk> War of 1874 . <eol> = = <unk> = = <eol> In 1873 , the building was renamed Little Rock Barracks and used as a barracks for married officers and their families . The building was drastically altered the inside and outside . Prior to renovation , a rear basement door provided the only entrance to the building , while the tower served as a hoist to move munitions between floors . By 1868 , front and rear <unk> had been added to the building , as well as interior walls and stairs , some of which remain today , including the central staircase . In 1880 , Douglas MacArthur was born on the northwest upper floor of this building while his father , Captain Arthur MacArthur , was stationed there . <eol> In the 1880s , the federal government began closing many small <unk> around the country in favor of smaller ones built near railroads for quick deployment . The arsenal commander received word from Washington that the Little Rock site must be abandoned \" not later than October 1 , 1890 . \" On April 12 , 1893 the tower building and the surrounding buildings were traded to the city of Little Rock for 1 @,@ 000 acres ( 4 km ² ) in North Little Rock under the condition that the building and land be \" forever exclusively devoted to the uses and purposes of a public park \" for 1 @,@ 000 acres ( 4 km ² ) in Big Rock Mountain on the north side of the Arkansas River , present day North Little Rock . That site later became Fort Logan H. Roots . All of the original buildings surrounding the Tower Building were demolished . <eol> = = Æsthetic Club = = <eol> In 1894 the Little Rock Æsthetic Club , one of the oldest women 's societies west of the Mississippi River , moved into the Tower Building . This was prompted due to increased membership and a need for larger , more permanent quarters . The previous year , club members working with women 's organizations throughout the state , raised money to <unk> the Arkansas Building of the Columbian Exposition at The Chicago World 's Fair . At the fair 's conclusion , artifacts from the exhibit were displayed in the Tower Building , with the Æsthetic Club invited to meet in the \" Columbian Room . \" <eol> Except for Æsthetic Club meetings , the Tower Building remained largely unoccupied for almost fifty years and suffered significant deterioration . The Æsthetic Club provided much @-@ needed financial support during the period and even paid the electric bill during the Great Depression . The Æsthetic Club is still headquartered in the Tower Building . <eol> = = Public use = = <eol> The building and the surrounding park were used for many public purposes throughout the early 20th century . The Tower Building served as headquarters for the United Confederate Veterans <unk> , May 15 – 18 , 1911 . Over 106 @,@ 000 Civil War veterans , the largest popular gathering in the history of the city up to that time , attended and were housed in the building or camped in the park , which had also become a popular camping area . Later the building served as an armory for the Arkansas National Guard . In 1912 , the second floor of the Tower Building became Little Rock 's first public library . In 1917 , Little Rock built a fire station in the park , that building is now gone . A band shell named for H. H. Foster also was built in the park during this time , but also no longer exists . In 1936 , Works Progress Administration built the Museum of Fine Arts , now called the Arkansas Arts Center , just south of the Tower Building . <eol> The arsenal was listed in the National Register of Historic Places in 1970 . Due to its association with the Camden Expedition of 1864 , the arsenal may be included in the Camden Expedition Sites National Historic Landmark designated in 1994 . <eol> In 1942 , the Tower Building was renovated due to the efforts of the Æsthetic Club , Little Rock philanthropist Frederick W. <unk> , and the Works Progress Administration . It became the new home of The Arkansas Museum of Natural History and Antiquities , which had been located in Little Rock City Hall . The museum remained in the tower building for approximately fifty @-@ five years . The area surrounding the Tower Building had been known as Arsenal Park when the first decommissioned and then later renamed City Park . Due to the efforts of Bernie Babcock , however , the city finally named it MacArthur Park in 1942 in honor of Douglas MacArthur . <eol> In 1997 , the Museum of Science and Natural History merged with the Little Rock Children 's Museum , which had been located in Union Station , to form the Arkansas Museum of Discovery . The new museum was relocated to a historic building in the Little Rock River Market District . The MacArthur Museum of Arkansas Military History opened on May 19 , 2001 in the Tower Building . The new museum 's goal is to educate and inform visitors about the military history of Arkansas , preserve the Tower Building , honor servicemen and <unk> of the United States and commemorate the birthplace of Douglas MacArthur . <eol>\n",
            "= <unk> Mary Barker = <eol> <unk> Mary Barker ( 28 June 1895 – 16 February 1973 ) was an English illustrator best known for a series of fantasy illustrations depicting fairies and flowers . Barker 's art education began in girlhood with correspondence courses and instruction at the Croydon School of Art . Her earliest professional work included <unk> cards and juvenile magazine illustrations , and her first book , Flower Fairies of the Spring , was published in 1923 . Similar books were published in the following decades . <eol> Barker was a devout Anglican , and donated her artworks to Christian fundraisers and missionary organizations . She produced a few Christian @-@ themed books such as The Children ’ s Book of Hymns and , in collaboration with her sister Dorothy , He Leadeth Me . She designed a stained glass window for St. Edmund 's Church , Pitlake , and her painting of the Christ Child , The Darling of the World Has Come , was purchased by Queen Mary . <eol> Barker was equally proficient in <unk> , pen and ink , oils , and <unk> . Kate Greenaway and the Pre @-@ <unk> were the principal influences on her work . She claimed to paint instinctively and rejected artistic theories . Barker died in 1973 . Though she published Flower Fairy books with spring , summer , and autumn themes , it wasn 't until 1985 that a winter collection was assembled from her remaining work and published posthumously . <eol> = = Biography = = <eol> = = = Early life = = = <eol> Barker was born the second daughter and youngest child of Walter Barker , a partner in a seed supply company and an amateur artist , and his wife Mary Eleanor ( Oswald ) Barker on 28 June 1895 at home at 66 Waddon Road in Croydon , Surrey , England . Barker was an <unk> as a child , and cared for at home by her parents . Later , her sister and elder by two years , Dorothy Oswald Barker , continued the care . <eol> The family of four was moderately well off , and belonged to the lower end of the upper middle class . A <unk> , a governess , and a cook to prepare special meals for Barker were hired . She spent much time in bed at home amusing herself with painting books and a nursery library that included the works of Kate Greenaway and Randolph Caldecott – two artists who exerted strong influences on her later art . <eol> = = = Art education and first professional work = = = <eol> Barker took correspondence courses in art , probably until about 1919 . In 1908 at 13 years , she entered an evening class at the Croydon School of Art , and attended the school into the 1940s . In time , she received a teaching position . <eol> In 1911 , Raphael Tuck & Sons bought four of Barker 's \" little drawings \" for half a sovereign , and published them as postcards . In October 1911 , she won second prize in the Croydon Art Society 's poster competition , and shortly afterward was elected the youngest member of the Society . The art critic for the Croydon Advertiser remarked , \" Her drawings show a remarkable freedom of spirit . She has distinct promise . \" <eol> Following her father ’ s death in June 1912 , the seventeen @-@ year @-@ old Barker submitted art and poetry to My Magazine , Child ’ s Own , Leading <unk> , and Raphael Tuck <unk> in an effort to support both her mother and sister . Her sister Dorothy taught kindergarten in two private schools before opening a kindergarten at home . She brought in some money for the family 's support while supervising the household . <eol> = = = Flower Fairies of the Spring , 1923 = = = <eol> Fairies became a popular theme in art and literature in the early 20th century following the releases of The Coming of the Fairies by Sir Arthur Conan Doyle , Peter Pan by <unk> <unk> , and the fairy @-@ themed work of Australian Ida <unk> <unk> . Queen Mary made such themes even more popular by sending <unk> postcards to friends during the 1920s . In 1918 , Barker produced a <unk> series depicting elves and fairies . <eol> In 1923 , Barker sent her flower fairy paintings to various publishers . Blackie paid £ 25 for 24 paintings with accompanying verses , but it wasn 't until publication of Flower Fairies of the Summer in 1925 that Barker received royalties for her work . Mary <unk> Clayton Calthrop , wife of author Dion Clayton Calthrop , wrote in April 1925 about Barker and Flower Fairies of the Spring : \" She has such exquisite taste , besides <unk> . \" <eol> = = = The Waldrons = = = <eol> In 1924 , the family moved into a four @-@ level , semi @-@ detached Victorian house at 23 The Waldrons . Barker had a studio built in the garden and her sister conducted a kindergarten in a room at the back of the house . The family lived <unk> and attended both St. Edmund 's and St. Andrew 's in Croydon – \" low \" churches for the less privileged . Barker sometimes incorporated portraits of her fellow parishioners in her religious works . She was described by Canon Ingram Hill as \" one of the pillars \" of St. Andrew 's . <eol> The children in the kindergarten modelled for the Flower Fairies until the kindergarten closed in 1940 . In an interview in 1958 , Barker said , \" My sister ran a kindergarten and I used to borrow her students for models . For many years I had an atmosphere of children about me – I never <unk> it . \" She also painted the children of relatives as well as Gladys <unk> , the <unk> ' young housekeeper , who posed for the Primrose Fairy in 1923 . The plants were painted from life , and if a specimen was not readily at hand , <unk> Gardens staff would provide her the specimens needed . Barker designed and built the Flower Fairy costumes , and based each on the flowers and leaves of the particular plant to be illustrated . The costumes were kept in a trunk in her studio along with wings made of twigs and <unk> . Each was broken down after an illustration was completed and the parts recycled for other costumes . She often referred to Dion Clayton Calthrop 's English Costume . <eol> = = = Middle years = = = <eol> In the late 1920s , Barker began to doubt she was doing enough for the church and considered focusing solely on sacred works . Family and friends recommended she continue secular and sacred works , which she did . <eol> Barker continued to attend evening classes at the Croydon Art School between the 1920s and the 1940s , eventually receiving a teaching position . She took <unk> trips to <unk> and Storrington in Sussex and to Cornwall and the southern coast with family and friends . She visited and stayed with artist Margaret <unk> in <unk> , Surrey and with family in <unk> , Near Whitby , North Yorkshire . <eol> In 1940 , the Barker 's live @-@ in maid retired , and Dorothy Barker closed her school at the back of the house in The Waldrons . She continued to supervise the household , and to give both her mother and sister the care they needed . Dorothy and her sister collaborated upon only two books : Our Darling 's First Book and the Christian @-@ themed , He Leadeth Me . In 1954 Dorothy Barker died of a heart attack . Barker was unable to pursue her art to any significant extent following her sister 's death , as all the care of her aged mother devolved upon her , but she did manage to begin planning a stained glass window design in her sister 's memory for St. Edmund 's , Pitlake . <eol> = = = Later life and death = = = <eol> Barker 's mother died in 1960 , and , in 1961 , Barker moved from 23 The Waldrons to 6 <unk> Avenue in Croydon . She restored a <unk> in Storrington , Sussex , England , bequeathed by her friend Edith Major , and named it St. Andrew 's . After taking up residence , her health began to deteriorate . She was in and out of nursing and <unk> homes , and tended by relatives and friends . <eol> Barker died at Worthing Hospital on 16 February 1973 , aged 77 years . Two funeral services were held – one in Storrington Church and one in Barker 's <unk> . Her ashes were scattered in Storrington churchyard . In 1989 , Frederick Warne , a division of Penguin Books since 1983 , acquired the Flower Fairies properties . <eol> = = Art = = <eol> Barker worked principally in <unk> with pen @-@ and @-@ ink , but she was equally competent in black @-@ and @-@ white , in oils , and in <unk> . She carried a <unk> with her for capturing interesting children . She once indicated , \" I have always tried to paint instinctively in a way that comes naturally to me , without any real thought or attention to artistic theories . \" <eol> Kate Greenaway was a childhood favorite and an influence on her art . Barker 's child subjects wear nostalgic clothing as Greenaway 's children do , though Barker 's children are less melancholy and less flat in appearance , due perhaps to advances in printing technology . Barker studied flowers with an analytical eye and was friend to children 's illustrator , Margaret <unk> . Along with Greenaway , illustrator Alice B. Woodward also influenced Barker 's work . <eol> The Pre @-@ <unk> were a strong , lifelong influence on Barker . She once indicated , \" I am to some extent influenced by them — not in any technical sense , but in the choice of subject matter and the feeling and atmosphere they could achieve . \" She admitted a fondness for the early paintings of John Everett Millais and \" the wonderful things \" of Edward <unk> @-@ Jones . <eol> = = = Depictions of children = = = <eol> Barker 's sketches , drawings , and paintings of children were given to friends or to the parents of the subjects , donated to charitable institutions and church sponsored events , or exhibited through various art organizations . She illustrated magazine covers , dust jackets , and produced series of postcards for Raphael Tuck and other publishers such as <unk> Children of the Allies ( 1915 ) , Seaside <unk> ( 1918 ) , and Shakespeare 's Boy and Girl Characters ( 1917 , 1920 ) . Her own Old Rhymes for All Times ( 1928 ) and The Lord of the Rushie River ( 1938 ) , a tale about a girl who lives among <unk> on a <unk> , were critically well received . Set about 1800 , Groundsel and Necklaces ( 1943 ) tells of a girl named Jenny who rescues her family from poverty through the agency of the fairies . The story features an old <unk> @-@ like man called Mr. <unk> and <unk> suggests a <unk> social consciousness . Simon the Swan , intended as a sequel to Rushie River was outlined in 1943 with Groundsel , but only developed in 1953 . It was published posthumously in 1988 and is critically considered less successful than Groundsel . <eol> = = = Christian @-@ themed works = = = <eol> Barker was a devout Christian , and produced religious @-@ themed works throughout her life . She published eight postcards and five guardian angel birthday cards for the Society for <unk> Christian Knowledge in 1916 and in 1923 respectively . Christmas cards were designed for The Girls ' Friendly Society over a 20 @-@ year period , and the first three designs sold out a combined printing of 46 @,@ 500 in 1923 . An original design for the society called The Darling of the World Has Come was purchased by Queen Mary for ₤ 5 @.@ 5 @.@ 0 in 1926 . The Croydon Art Society hung Barker 's booklet cover design for the Society for the <unk> of the Gospel in its November 1919 exhibition . <eol> Religious @-@ themed books include The Children 's Book of Hymns ( 1929 ) and He Leadeth Me ( 1933 ) , the latter written in collaboration with her sister . Major religious works include the <unk> in oil , The Feeding of the Five Thousand ( 1929 ) , for the chapel in Llandaff House , a home for destitute women at Penarth , Wales , and The Parable of the Great Supper ( 1934 ) for St. George 's Chapel , Waddon . The Feeding has since disappeared , and only a black @-@ and @-@ white photograph dated 1929 <unk> the work . In 1941 , she completed oil panels on the subject of the seven sacraments for the baptismal font at St. Andrew 's , South Croydon . She designed baptismal rolls for the wall behind the font in 1948 and 1962 . In 1946 , she completed the 4 x 7 <unk> oil painting , Out of Great <unk> , for the Memorial Chapel of <unk> Methodist Church . Following the death of her sister in 1954 , Barker began designs for a stained glass memorial window depicting Christ preparing to wash the feet of his disciples . Her last religious @-@ themed work , it was installed in St. Edmund 's , Pitlake , in 1962 . <eol> = = Works = = <eol> = = = Cards = = = <eol> <unk> Children of the Allies ; J. Salmon , 1916 <eol> National Mission ; Society for the Preservation of Christian Knowledge , 1916 <eol> Shakespeare 's Boy Characters ; C. W. Faulkner , 1917 <eol> Shakespeare 's Girl Characters ; C. W. Faulkner , 1920 <eol> Seaside Holiday ; J. Salmon , 1918 , 1921 <eol> <unk> and Fairies ; S. Harvey , 1918 <eol> Guardian Angel ; Society for the Preservation of Christian Knowledge , 1923 <eol> Christmas cards ; Girls ' Friendly Society , 1920s , 1930s <eol> Christmas cards ( US ) ; Barton @-@ Colton , 1920s , 1930s <eol> Beautiful Bible Pictures ; Blackie , 1932 <eol> = = = Books = = = <eol> Flower Fairies of the Spring ; Blackie , 1923 <eol> Spring Songs with Music ; Blackie , 1923 <eol> Flower Fairies of the Summer ; Blackie , 1925 <eol> Child <unk> in Picture and Verse ( by M. K. <unk> ) ; Blackie , 1925 <eol> Flower Fairies of the Autumn ; Blackie , 1926 <eol> Summer Songs with Music ; Blackie , 1926 <eol> The Book of the Flower Fairies ; Blackie , 1927 <eol> Autumn Songs with Music ; Blackie , 1927 <eol> Old Rhymes for All Times ; Blackie , 1928 <eol> The Children ’ s Book of Hymns ; Blackie , 1929 ; <unk> . 1933 <eol> Our Darling ’ s First Book ( written in collaboration with Dorothy Barker ) ; Blackie , 1929 <eol> The Little Picture Hymn Book ; Blackie , 1933 <eol> Rhymes New and Old ; Blackie , 1933 <eol> A Flower Fairy Alphabet ; Blackie , 1934 <eol> A Little Book of Old Rhymes ; Blackie , 1936 <eol> He Leadeth Me ( written in collaboration with Dorothy Barker ) ; Blackie , 1936 <eol> A Little Book of Rhymes New and Old ; Blackie , 1937 <eol> The Lord of the Rushie River ; Blackie , 1938 <eol> Flower Fairies of the Trees ; Blackie , 1940 <eol> When Spring <unk> In at the Window ; Blackie , 1942 <eol> A Child ’ s Garden of <unk> ( Robert Louis Stevenson ) ; Blackie , 1944 <eol> Flower Fairies of the Garden ; Blackie , 1944 <eol> Groundsel and Necklaces ; Blackie , 1946 ; reprinted as Fairy Necklaces <eol> Flower Fairies of the <unk> ; Blackie , 1948 <eol> Flower Fairies of the Flowers and Trees ; Blackie , 1950 <eol> Lively Stories ; Macmillan , 1954 <eol> The Flower Fairy Picture Book ; Blackie , 1955 <eol> Lively Numbers ; Macmillan , 1957 <eol> Lively Words ; Macmillan , 1961 . <eol> The Sand , the Sea and the Sun ; Gibson , 1970 <eol> = = = = <unk> published = = = = <eol> Flower Fairies of the Winter ; Blackie , 1985 <eol> Simon the Swan ; Blackie , 1988 <eol> Flower Fairies of the Seasons ; <unk> / Blackie , 1988 <eol> A Little Book of <unk> and Hymns ; Frederick Warne , 1994 <eol> A Flower Fairies Treasury ; Frederick Warne , 1997 <eol> <unk> ; Frederick Warne , 2005 <eol> Wild Cherry Makes A Wish ; ( collaboration with <unk> Le <unk> ) Frederick Warne , 2006 <eol> How to find Flower Fairies ; Frederick Warne , 2007 <eol> Return to <unk> ; Frederick Warne , 2008 <eol> = = = Book covers = = = <eol> A New Epiphany ; Society for the Preservation of Christian Knowledge , 1919 <eol> 43 <unk> ; Blackie , 1920s , 1930s <eol> = = = Religious works = = = <eol> St. Cecily 's Garden ; 1920 <eol> <unk> roll design ; St. Edmund 's , Pitlake , 1922 <eol> Banner design ; St. Mary 's , <unk> , 1923 <eol> The Feeding of the Five Thousand ; <unk> <unk> , chapel at Penarth , Wales ; 1929 <eol> The Parable of the Great Supper ; <unk> , St. George 's chapel , Waddon <eol> The Seven <unk> ; baptismal font panels , St. Andrew 's , Croydon <eol> St. John the Baptist ; central banner panel , <unk> church , 1943 <eol> <unk> , sword , and shield ; mount for a list of men and woman serving in the Forces , St. Andrews , Croydon , 1943 <eol> <unk> rolls ; St. Andrews , Croydon , 1948 , 1962 <eol> The font in St Andrew 's Church , South Croydon <eol> Out of Great <unk> ; memorial chapel , <unk> <unk> church , 1948 <eol> I Am Among You As He That <unk> ; stained glass window design , St. Edmund 's , Pitlake , 1962 <eol>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##** Adding <sos> and <eos> (integer symbols) before the start and end of every sentence in dataset **##\n",
        "for i in range(len(dataset)):\n",
        "    dataset[i] = np.insert(dataset[i], 0, SOS_TOKEN)\n",
        "    dataset[i] = np.append(dataset[i], EOS_TOKEN)"
      ],
      "metadata": {
        "id": "esL0Yw-jMVAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0])\n",
        "print(' '.join([VOCAB[i] for i in dataset[0]]))\n",
        "print(' '.join([VOCAB[i] for i in dataset[1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxdaQOhNYVa1",
        "outputId": "d62d864e-f487-499c-9daa-f4abed3a8984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33278  1420 13859 ...    79  1417 33279]\n",
            "<sos> = Valkyria Chronicles III = <eol> Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . <eol> The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . <eol> It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . <eol> = = Gameplay = = <eol> As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through <unk> text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main <unk> , although they take a very minor role . <eol> The game 's battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters ' turns . Each character has a field and distance of movement limited by their Action <unk> . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant <unk> to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special <unk> that grant them temporary <unk> on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without <unk> his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become <unk> , while Imca can target multiple enemy units with her heavy weapon . <eol> Troops are divided into five classes : Scouts , <unk> , Engineers , <unk> and Armored Soldier . <unk> can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games ' method of distributing to different unit types . <eol> = = Plot = = <eol> The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign <unk> , and military offenders whose real names are erased from the records and <unk> officially referred to by numbers . <unk> by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task , exemplified by their motto , <unk> <unk> , meaning \" Always Ready . \" The three main characters are <unk> Kurt Irving , an army officer falsely accused of treason who wishes to redeem himself ; Ace <unk> Imca , a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and <unk> Riela <unk> , a seemingly <unk> young woman who is unknowingly a descendant of the Valkyria . Together with their fellow squad members , these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven , consisting of mostly Darcsen soldiers . <eol> As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible <unk> in order to send them on missions that would otherwise make Gallia lose face in the war . While at times this works to their advantage , such as a successful incursion into Imperial territory , other orders cause certain members of the 422nd great distress . One such member , <unk> , becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven , attached to the ideal of Darcsen independence proposed by their leader , Dahau . At the same time , elements within Gallian Army Command move to erase the Nameless in order to protect their own interests . <unk> by both allies and enemies , and combined with the presence of a traitor within their ranks , the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort . This continues until the Nameless 's commanding officer , Ramsey Crowe , who had been kept under house arrest , is escorted to the capital city of <unk> in order to present evidence <unk> the weary soldiers and expose the real traitor , the Gallian General that had accused Kurt of Treason . <eol> <unk> due to these events , and partly due to the major losses in manpower Gallia suffers towards the end of the war with the Empire , the Nameless are offered a formal position as a squad in the Gallian Army rather than serve as an anonymous shadow force . This is short @-@ lived , however , as following Maximilian 's defeat , Dahau and Calamity Raven move to activate an ancient <unk> super weapon within the Empire , kept secret by their benefactor . Without the support of Maximilian or the chance to prove themselves in the war with Gallia , it is Dahau 's last <unk> card in creating a new Darcsen nation . As an armed Gallian force invading the Empire just following the two nations ' cease @-@ fire would certainly wreck their newfound peace , Kurt decides to once again make his squad the Nameless , asking Crowe to list himself and all under his command as killed @-@ in @-@ action . Now owing allegiance to none other than themselves , the 422nd confronts Dahau and destroys the <unk> weapon . Each member then goes their separate ways in order to begin their lives <unk> . <eol> = = Development = = <eol> Concept work for Valkyria Chronicles III began after development finished on Valkyria Chronicles II in early 2010 , with full development beginning shortly after this . The director of Valkyria Chronicles II , Takeshi Ozawa , returned to that role for Valkyria Chronicles III . Development work took approximately one year . After the release of Valkyria Chronicles II , the staff took a look at both the popular response for the game and what they wanted to do next for the series . Like its predecessor , Valkyria Chronicles III was developed for PlayStation Portable : this was due to the team wanting to refine the mechanics created for Valkyria Chronicles II , and they had not come up with the \" revolutionary \" idea that would warrant a new entry for the PlayStation 3 . Speaking in an interview , it was stated that the development team considered Valkyria Chronicles III to be the series ' first true sequel : while Valkyria Chronicles II had required a large amount of trial and error during development due to the platform move , the third game gave them a chance to improve upon the best parts of Valkyria Chronicles II due to being on the same platform . In addition to Sega staff from the previous games , development work was also handled by <unk> The original scenario was written <unk> <unk> , while the script was written by Hiroyuki <unk> , <unk> <unk> , <unk> <unk> , <unk> <unk> and <unk> <unk> . Its story was darker and more somber than that of its predecessor . <eol> The majority of material created for previous games , such as the <unk> system and the design of maps , was carried over . Alongside this , improvements were made to the game 's graphics and some elements were expanded , such as map layouts , mission structure , and the number of playable units per mission . A part of this upgrade involved creating unique <unk> models for each character 's body . In order to achieve this , the cooperative elements incorporated into the second game were removed , as they took up a large portion of memory space needed for the improvements . They also adjusted the difficulty settings and ease of play so they could appeal to new players while retaining the essential components of the series ' gameplay . The newer systems were decided upon early in development . The character designs were done by <unk> Honjou , who had worked on the previous Valkyria Chronicles games . When creating the Nameless Squad , Honjou was faced with the same problem he had had during the first game : the military uniforms essentially destroyed character individuality , despite him needing to create unique characters the player could identify while maintaining a sense of reality within the Valkyria Chronicles world . The main color of the Nameless was black . As with the previous Valkyria games , Valkyria Chronicles III used the <unk> graphics engine . The anime opening was produced by Production I.G. <eol> = = = Music = = = <eol> The music was composed by Hitoshi Sakimoto , who had also worked on the previous Valkyria Chronicles games . When he originally heard about the project , he thought it would be a light tone similar to other Valkyria Chronicles games , but found the themes much darker than expected . An early theme he designed around his original vision of the project was rejected . He <unk> the main theme about seven times through the music production due to this need to <unk> the game . The main theme was initially recorded using orchestra , then Sakimoto removed elements such as the guitar and bass , then adjusted the theme using a synthesizer before <unk> segments such as the guitar piece on their own before incorporating them into the theme . The rejected main theme was used as a hopeful tune that played during the game 's ending . The battle themes were designed around the concept of a \" modern battle \" divorced from a fantasy scenario by using modern musical instruments , constructed to create a sense of <unk> . While Sakimoto was most used to working with synthesized music , he felt that he needed to incorporate live instruments such as orchestra and guitar . The guitar was played by <unk> <unk> , who also arranged several of the later tracks . The game 's opening theme song , \" If You Wish for ... \" ( <unk> , <unk> Kimi <unk> <unk> <unk> ) , was sung by Japanese singer May 'n . Its theme was the reason soldiers fought , in particular their wish to protect what was precious to them rather than a sense of responsibility or duty . Its lyrics were written by <unk> <unk> , who had worked on May 'n on previous singles . <eol> = = = Release = = = <eol> In September 2010 , a teaser website was revealed by Sega , hinting at a new Valkyria Chronicles game . In its September issue , Famitsu listed that Senjō no Valkyria 3 would be arriving on the PlayStation Portable . Its first public appearance was at the 2010 Tokyo Game Show ( TGS ) , where a demo was made available for journalists and attendees . During the publicity , story details were kept <unk> so as not to <unk> too much for potential players , along with some of its content still being in flux at the time of its reveal . To promote the game and detail the story leading into the game 's events , an episodic Flash visual novel written by <unk> began release in January 2011 . The game was released January 27 , 2011 . During an interview , the development team said that the game had the capacity for downloadable content ( DLC ) , but that no plans were finalized . Multiple DLC maps , featuring additional missions and <unk> characters , were released between February and April 2011 . An expanded edition of the game , Valkyria Chronicles III Extra Edition , released on November 23 , 2011 . <unk> and sold at a lower price than the original , Extra Edition game with seven additional episodes : three new , three chosen by staff from the game 's DLC , and one made available as a pre @-@ order bonus . People who also owned the original game could transfer their save data between versions . <eol> Unlike its two predecessors , Valkyria Chronicles III was not released in the west . According to Sega , this was due to poor sales of Valkyria Chronicles II and the general unpopularity of the PSP in the west . An unofficial fan translation patch began development in February 2012 : players with a copy of Valkyria Chronicles III could download and apply the patch , which translated the game 's text into English . <unk> with the Extra Edition , the patch was released in January 2014 . <eol> = = Reception = = <eol> On its day of release in Japan , Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts . By early February , the game sold 102 @,@ <unk> units , coming in second overall to The Last Story for the Wii . By the end of the year , the game had sold just over 152 @,@ 500 units . <eol> Famitsu enjoyed the story , and were particularly pleased with the improvements to gameplay . Japanese gaming site Game Watch <unk> , despite negatively noting its pacing and elements recycled from previous games , was generally positive about its story and characters , and found its gameplay entertaining despite off @-@ putting difficulty spikes . <unk> writer <unk> <unk> , in a \" Play Test \" article based on the game 's <unk> demo , felt that Valkyria Chronicles III provided a \" profound feeling of closure \" for the Valkyria Chronicles series . He praised its gameplay despite annoying limitations to aspects such as special abilities , and positively noted its shift in story to a tone similar to the first game . <eol> PlayStation Official Magazine - UK praised the story 's <unk> of Gallia 's moral standing , art style , and most points about its gameplay , positively noting the latter for both its continued quality and the tweaks to balance and content . Its one major criticism were multiple difficulty spikes , something that had affected the previous games . Heath Hindman of gaming website PlayStation <unk> praised the addition of non @-@ linear elements and improvements or removal of mechanics from Valkyria Chronicles II in addition to praising the returning gameplay style of previous games . He also positively noted the story 's serious tone . Points criticized in the review were recycled elements , awkward cutscenes that seemed to include all characters in a scene for no good reason , pacing issues , and occasional problems with the game 's AI . <eol> In a preview of the TGS demo , Ryan Geddes of IGN was left excited as to where the game would go after completing the demo , along with enjoying the improved visuals over Valkyria Chronicles II . Kotaku 's Richard <unk> was highly positive about the game , citing is story as a return to form after Valkyria Chronicles II and its gameplay being the best in the series . His main criticisms were its length and gameplay repetition , along with expressing regret that it would not be localized . <eol> = = Legacy = = <eol> Kurt and Riela were featured in the Nintendo 3DS crossover Project X Zone , representing the Valkyria series . Media.Vision would return to the series to develop Valkyria : Azure Revolution , with Ozawa returning as director . Azure Revolution is a role @-@ playing video game for the PlayStation 4 that forms the beginning of a new series within the Valkyria franchise . <eol> = = = Adaptations = = = <eol> Valkyria Chronicles 3 was adapted into a two @-@ episode original video animation series in the same year of its release . <unk> Senjō no Valkyria 3 : <unk> <unk> no <unk> ( <unk> <unk> , lit . Valkyria of the Battlefield 3 : The <unk> Taken for <unk> 's Sake ) , it was originally released through PlayStation Network and <unk> between April and May 2011 . The initially @-@ planned release and availability period needed to be extended due to a stoppage to <unk> during the early summer of that year . It later released for DVD on June 29 and August 31 , 2011 , with separate \" Black \" and \" Blue \" editions being available for purchase . The anime is set during the latter half of Valkyria Chronicles III , detailing a mission by the Nameless against their Imperial rivals Calamity Raven . The anime was first announced in November 2010 . It was developed by A @-@ 1 Pictures , produced by Shinji <unk> , directed by <unk> <unk> , and written by Hiroshi <unk> . Sakimoto 's music for the game was used in the anime . <eol> The anime 's title was inspired by the principle purpose of the Nameless : to suffer in battle for the goals of others . A <unk> attached to the project during development was \" The Road to <unk> \" , which referenced the <unk> Tank Museum in Moscow . The game 's main theme was how the characters regained their sense of self when stripped of their names and identities , along with general themes focused on war and its consequences . While making the anime , the production team were told by Sega to make it as realistic as possible , with the consequence that the team did extensive research into aspects such as what happened when vehicles like tanks were overturned or damaged . Due to it being along the same timeline as the original game and its television anime adaptation , the cast of Valkyria Chronicles could make appearances , which pleased the team . The opening theme , \" <unk> ( Light ) <unk> \" ( <unk> @-@ <unk> ) , was sung by Japanese singer <unk> . The ending theme , \" <unk> the Flowers of Light Will Bloom \" ( <unk> , <unk> <unk> <unk> no <unk> ) , was sung by <unk> <unk> . Both songs ' lyrics were written by their respective artists . <eol> Two manga adaptations were produced , following each of the game 's main female protagonists Imca and Riela . They were Senjō no Valkyria 3 : <unk> <unk> <unk> no <unk> ( 戦場のヴァルキュリア3 <unk> , lit . Valkyria of the Battlefield 3 : The Flower of the Nameless Oath ) , illustrated by <unk> <unk> and eventually released in two volumes after being serialized in Dengeki <unk> between 2011 and 2012 ; and Senjō no Valkyria 3 : <unk> <unk> no <unk> <unk> ( 戦場のヴァルキュリア3 <unk> , lit . Valkyria of the Battlefield 3 <unk> <unk> of the Crimson Fate ) , illustrated by <unk> <unk> and eventually released in a single volume by Kadokawa Shoten in 2012 . <eol> <eos>\n",
            "<sos> = Tower Building of the Little Rock Arsenal = <eol> The Tower Building of the Little Rock Arsenal , also known as U.S. Arsenal Building , is a building located in MacArthur Park in downtown Little Rock , Arkansas . Built in 1840 , it was part of Little Rock 's first military installation . Since its decommissioning , The Tower Building has housed two museums . It was home to the Arkansas Museum of Natural History and Antiquities from 1942 to 1997 and the MacArthur Museum of Arkansas Military History since 2001 . It has also been the headquarters of the Little Rock Æsthetic Club since 1894 . <eol> The building receives its name from its distinct octagonal tower . Besides being the last remaining structure of the original Little Rock Arsenal and one of the oldest buildings in central Arkansas , it was also the birthplace of General Douglas MacArthur , who became the supreme commander of US forces in the South Pacific during World War II . It was also the starting place of the Camden Expedition . In 2011 it was named as one of the top 10 attractions in the state of Arkansas by <unk> <eol> = = Construction = = <eol> The arsenal was constructed at the request of Governor James <unk> Conway in response to the perceived dangers of frontier life and fears of the many Native Americans who were passing through the state on their way to the newly established Oklahoma Territory . Thirty @-@ six acres were appropriated on the outskirts of Little Rock by Major Robert B. Lee of the U.S. Army . The land had been previously used as a racetrack by the local jockey club . John <unk> Walker , a builder for the Federal Government , supervised the construction . Originally $ 14 @,@ 000 was allocated for the construction of the arsenal , but proved inadequate . The budget was later increased to $ 30 @,@ 000 . Work began on the Tower Building in 1840 , and it was the first permanent structure of the arsenal to be built . Being originally constructed to store ammunition , the building was designed with 3 @-@ foot @-@ thick ( 0 @.@ 91 m ) exterior walls . The original plans called for it to be built of stone , however , masonry was used instead . The Arkansas Gazette referred to the structure as \" A splendid specimen of masonry \" . <eol> = = Civil War = = <eol> For several years the arsenal , which was owned by the federal government , served as a simple arms depot and was staffed with only a handful of soldiers . But in November 1860 , with the American Civil War on the horizon , a company of the Second United States Artillery , consisting of sixty @-@ five men , was transferred to Little Rock under the command of Captain James Totten . On January 15 , 1861 , the state legislature decided to hold a referendum to determine if a state convention should be held to consider the issue of <unk> and to elect delegates to such a convention . It was planned for February 18 ; however , events at the arsenal , would not wait . On January 28 , then Governor Henry Massey Rector informed Captain Totten that he and his soldiers would be \" permitted to remain in the possession of the Federal officers until the State , by authority of the people , shall have determined to <unk> their connection with the General Government , \" Totten responded to this by telling the Governor that his orders came from the United States Government and began a desperate but ultimately futile dispatch of letters and <unk> asking for reinforcements , although rumors were widely spread that they were already coming . The first telegraph wire to span between Little Rock and Memphis had recently been completed . Local attorney John M Harrel was asked to compose the first telegraph dispatched from Arkansas 's capital . In his message , Harrel reported unconfirmed rumors that more federal troops had been sent to reinforce the Little Rock Arsenal . <eol> The United States troops at the outposts of the western frontier of the state and in the Indian nation have all been recalled from winter quarters to reinforce the garrison at Fort Smith . The garrison at Fort Smith had been previously transferred to the United States Arsenal in this city ( Little Rock ) . The arsenal is one of the richest <unk> of military stores in the United States and is supposed to be the ultimate destination of the <unk> [ sic ] ordered from the frontier . <eol> <unk> M Harrel <unk> , January 31 , 1861 <eol> The item was intended simply as a piece of news , but telegraph lines quickly spread the news throughout the state , <unk> procession sentiment . The rumor was interpreted by some <unk> as a call from the governor to assemble to help expel the federal troops from the arsenal . By February 5 , six militia units , consisting of 1 @,@ 000 men , with a guarantee that the numbers could be increased to 5 @,@ 000 if the situations deemed it necessary , had assembled in Little Rock . Governor Rector vehemently denied ordering the troops to assemble or giving any order at all in connection with the troops . Faced with the fact that the military had assembled believing they were following his orders and the consensus of the citizens of Little Rock against any armed conflict between the civilian army and federal troops , Governor Rector was forced to take control of the situation . On February 6 , he sent a formal demand for surrender of the arsenal to Captain Totten , <eol> This movement is prompted by the feeling that <unk> the citizens of this State that in the present emergency the arms and munitions of war in the Arsenal should be under the control of the State authorities , in order to their security . This movement , although not authorized by me , has assumed such an aspect that it becomes my duty , as the executive of this <unk> , to <unk> my official authority to prevent a collision between the people of the State and the Federal troops under your command . I therefore demand in the name of the State the delivery of the possession of the Arsenal and munitions of war under your charge to the State authorities , to be held subject to the action of the convention to be held on the 4th of March next . <eol> Perhaps because Abraham Lincoln had not yet been inaugurated as President , Captain Totten received no instructions from his superiors and was forced to withdraw his troops . He agreed to surrender the arsenal as long as the governor agreed to three provisions : <eol> The governor would take possession of the arsenal in the name of the United States . <eol> The soldiers would be allowed safe passage in any direction carrying any personal and public property besides munitions of war . <eol> The soldiers would be allowed to march away as men leaving under orders , not as conquered and surrendering soldiers . <eol> On the morning of February 8 , 1861 , Rector and Totten signed an agreement placing the arsenal in the hands of state officials . That afternoon , the citizen militia marched to the arsenal with Governor Rector at its head . All of the federal troops had left at this point , except Totten who had stayed behind to listen to the Governor 's speech and to hand the arsenal over in person . <eol> The Little Rock Arsenal was classified in 1860 as an \" arsenal of deposit , \" meaning that it was simply a warehouse for the storage of weapons intended for the use of the state militia in times of crisis . Thus there were no substantial operations for ordnance fabrication or repairs , nor for the manufacture of cartridges at the time the Arsenal fell into State hands . Most of these operations were started from scratch through the efforts of the Arkansas Military Board . <eol> Inside the Little Rock Arsenal after its seizure in February , 1861 , the Confederates <unk> some 10 @,@ 247 weapons , 250 @,@ 000 musket cartridges , and 520 @,@ 000 percussion caps , as well as the four bronze cannon of Totten 's battery . Long arms in the Arsenal 's inventory consisted of : <eol> M1822 .69 cal ( flintlock ) 5 @,@ 625 <eol> M1822 .69 cal ( percussion @-@ converted ) 53 <eol> <unk> .69 cal smoothbore ( percussion ) 357 <eol> <unk> <unk> cal rifle @-@ <unk> 900 <eol> <unk> common rifles 125 <eol> <unk> rifle ( \" Mississippi Rifle \" ) 54 <eol> <unk> <unk> 2 <eol> Hall 's <unk> 267 <eol> Hall 's rifles ( flintlock ) 2 @,@ 864 <eol> Total 10 @,@ 247 <eol> Of this number , approximately <unk> weapons were <unk> , or ready @-@ for @-@ issue . Note there were only 1 @,@ 364 percussion weapons available . <unk> of the weapons found in the Arsenal is somewhat sketchy , but from various records it can be surmised that the 5th , 6th , 7th , and 8th Arkansas Infantry Regiments , mustered in June , 1861 , were issued <unk> / M1822 .69 caliber <unk> . The 9th and 10th Arkansas , four companies of Kelly 's 9th Arkansas Battalion , and the 3rd Arkansas Cavalry Regiment were issued flintlock Hall 's Rifles . The units comprising the infantry force of Van Dorn 's Army of the West were the 1st and 2nd Arkansas Mounted Rifles were also armed with M1822 <unk> from the Little Rock Arsenal . By the time the 11th and 12th Arkansas Infantry Regiments mustered in at Little Rock , the supply of arms had been almost completely exhausted , and only old \" <unk> \" weapons were left . <eol> Most of the equipment , arms , and machinery at the Little Rock Arsenal was removed to east of the Mississippi River by order of <unk> Gen. Earl Van Dorn in April and May 1862 , and accountability for it is lost at that point . By all appearances , the equipment was sent down the river to Napoleon , Arkansas , and from there to Jackson Mississippi , where it was probably destroyed during the <unk> campaign in the early summer of 1863 . <eol> Major General Thomas C. Hindman , sent to command the district of Arkansas in May , 1862 , found the state nearly destitute of military material . Hindman established another armory at Arkadelphia , and revived the Little Rock Arsenal as a collection point and depot for <unk> and ammunition manufacture for small arms . Hindman recorded : <eol> \" Machinery was made for manufacturing percussion caps and small arms , and both were turned out in small quantity , but of excellent quality . Lead mines were opened and worked , and a chemical laboratory was established and successfully operated in aid of the Ordnance Department and in the manufacture of <unk> , <unk> oil , spirits of <unk> , the various <unk> of iron , and other valuable medicines . Most of these works were located at or near Arkadelphia on the <unk> River , 75 miles south from Little Rock . The tools , machinery , and the material were gathered <unk> or else made by hand labor . Nothing of this sort had been before attempted on Government account in Arkansas to my knowledge , except for the manufacture of small arms , the machinery for which was taken away by General Van Dorn and there was neither capital nor sufficient enterprise among the citizens to engage in such undertakings <unk> A further supply , along with lead and caps , was procured from the citizens of Little Rock and vicinity by donation , purchases , and <unk> . <eol> This ammunition , and that which I brought with me , was rapidly prepared for use at the Laboratory established at the Little Rock Arsenal for that purpose . As illustrating as the <unk> <unk> of material in the country , the fact may be stated that it was found necessary to use public documents of the State Library for cartridge paper . <unk> were employed or conscripted , tools purchased or impressed , and the repair of the damaged guns I brought with me and about an equal number found at Little Rock commenced at once . But , after inspecting the work and observing the spirit of the men I decided that a garrison 500 strong could hold out against Fitch and that I would lead the remainder - about 1500 - to <unk> 'l <unk> as soon as shotguns and rifles could be obtained from Little Rock instead of <unk> and lances , with which most of them were armed . Two days <unk> before the change could be effected . \" <eol> The Confederate ordnance establishment at Little Rock was reactivated in August , 1862 . Looking around for a suitable person to head this activity , General Hindman turned to the Confederate Navy and borrowed Lieutenant John W. Dunnington . Lt. Dunnington was the commander of the gunboat <unk> <unk> , which had been brought to Little Rock in hopes of converting it to an ironclad . Dunnington was selected to head the ordnance works at Little Rock , and although he continued to draw his pay from the Confederate Navy Department , he was placed in charge of all Confederate ordnance activities ( which included artillery functions ) there with the rank of lieutenant colonel . <eol> Lt. Col. Dunnington 's \" <unk> for the month of August , 1862 , at Little Rock Arsenal , <unk> , \" are found in Vol . 149 , Chapter IV of the \" <unk> Rebel Ordnance Records , \" and are most enlightening as to the scope of Confederate ordnance activities at Little Rock during this crucial time . According to Dunnington , \" When I assumed command at this Post , all material had been removed to Arkadelphia . There were no persons employed . No shops were open for repair of arms or for <unk> ammunition . Material , tools , etc . , had to be procured as well as the employment of laborers . Work commenced the last part of the month . \" <eol> The military force at Little Rock under Dunnington 's command consisted of four officers : himself , Major John B. <unk> , Captain <unk> Green , and 2nd Lt. <unk> Murphy . In addition to these , he had 20 enlisted men and a civilian force composed of a <unk> , 2 clerks , 3 <unk> for repairing small arms , a <unk> , 26 laborers in the ammunition laboratory , and a carpenter for making packing boxes . <eol> During the month of August , 1862 , the following work was performed : \" <unk> : one pair of musket bullet moulds ; 10 @,@ 000 buck & ball shot cartridges ; repaired : 750 <unk> , shotguns , and rifles ; received and repaired : ordnance stores and <unk> ; performed : guard , office , and police duties ; inspected : <unk> at Camden and Arkadelphia . \" <eol> Lt. Col. Dunnington continued to build up his works at Little Rock until November 1862 , when Captain Sanford C. Faulkner ( composer of The Arkansas Traveler ) was placed in charge of the Arsenal . Dunnington presumably returned to his naval duties and the <unk> . <eol> A \" Summary of the Work <unk> for November , 1862 , Little Rock Arsenal \" shows : <unk> : <eol> 75 @,@ 000 buck & ball cartridges - percussion <eol> 14 @,@ 000 buck & ball cartridges - flint <eol> 275 paper <unk> <eol> 117 rounds , 6 @-@ pounder <unk> shot <eol> 130 rounds , 6 @-@ pounder ball shot <eol> 96 ammunition packing boxes <eol> <unk> : <eol> 2 @,@ 236 shotguns and rifles ( repaired mostly for troops in service ) <eol> 23 pistols ( repaired mostly for troops in service ) <eol> <unk> & <unk> : <eol> <unk> packages of ordnance and ordnance stores received and mostly issued to troops in service . <eol> <unk> and painted : <eol> 4 gun carriages <eol> Performed : <eol> Guard , office , and police duties . <eol> Perhaps the most <unk> points of the above \" Summary of Work \" and those for following months are that the standard ammunition made was . \" buck & ball \" , indicating that the .69 caliber <unk> and shotguns remained the predominant caliber weapon in use , and of this , nearly one sixth or more of all small arms ammunition was still for flintlock weapons , indicating that no less than a sixth of the Confederate troops in this vicinity were still armed with obsolete flintlock weapons . <eol> The \" <unk> of Work done at Little Rock Arsenal , <unk> \" continue at about the same pace and scale from August 1862 until August 1863 . <unk> to the \" Summary \" for August , 1863 is the ominous <unk> , \" During the last week in the month , nearly all stores at the Arsenal have been packed and sent to Arkadelphia , in obedience to orders from Chief of Ordnance , District of Arkansas . \" This then marks the beginning of the evacuation of ordnance activities from Little Rock , with the city being surrendered to the advancing Federal troops of Frederick Steele 's Arkansas Expedition on September 11 , 1863 . <eol> In 1864 , after Little Rock fell to the Union Army and the arsenal had been recaptured , General <unk> Steele marched 8 @,@ 500 troops from the arsenal beginning the Camden Expedition . <eol> The arsenal was briefly seized once more by Joseph Brooks loyalists during the Brooks @-@ <unk> War of 1874 . <eol> = = <unk> = = <eol> In 1873 , the building was renamed Little Rock Barracks and used as a barracks for married officers and their families . The building was drastically altered the inside and outside . Prior to renovation , a rear basement door provided the only entrance to the building , while the tower served as a hoist to move munitions between floors . By 1868 , front and rear <unk> had been added to the building , as well as interior walls and stairs , some of which remain today , including the central staircase . In 1880 , Douglas MacArthur was born on the northwest upper floor of this building while his father , Captain Arthur MacArthur , was stationed there . <eol> In the 1880s , the federal government began closing many small <unk> around the country in favor of smaller ones built near railroads for quick deployment . The arsenal commander received word from Washington that the Little Rock site must be abandoned \" not later than October 1 , 1890 . \" On April 12 , 1893 the tower building and the surrounding buildings were traded to the city of Little Rock for 1 @,@ 000 acres ( 4 km ² ) in North Little Rock under the condition that the building and land be \" forever exclusively devoted to the uses and purposes of a public park \" for 1 @,@ 000 acres ( 4 km ² ) in Big Rock Mountain on the north side of the Arkansas River , present day North Little Rock . That site later became Fort Logan H. Roots . All of the original buildings surrounding the Tower Building were demolished . <eol> = = Æsthetic Club = = <eol> In 1894 the Little Rock Æsthetic Club , one of the oldest women 's societies west of the Mississippi River , moved into the Tower Building . This was prompted due to increased membership and a need for larger , more permanent quarters . The previous year , club members working with women 's organizations throughout the state , raised money to <unk> the Arkansas Building of the Columbian Exposition at The Chicago World 's Fair . At the fair 's conclusion , artifacts from the exhibit were displayed in the Tower Building , with the Æsthetic Club invited to meet in the \" Columbian Room . \" <eol> Except for Æsthetic Club meetings , the Tower Building remained largely unoccupied for almost fifty years and suffered significant deterioration . The Æsthetic Club provided much @-@ needed financial support during the period and even paid the electric bill during the Great Depression . The Æsthetic Club is still headquartered in the Tower Building . <eol> = = Public use = = <eol> The building and the surrounding park were used for many public purposes throughout the early 20th century . The Tower Building served as headquarters for the United Confederate Veterans <unk> , May 15 – 18 , 1911 . Over 106 @,@ 000 Civil War veterans , the largest popular gathering in the history of the city up to that time , attended and were housed in the building or camped in the park , which had also become a popular camping area . Later the building served as an armory for the Arkansas National Guard . In 1912 , the second floor of the Tower Building became Little Rock 's first public library . In 1917 , Little Rock built a fire station in the park , that building is now gone . A band shell named for H. H. Foster also was built in the park during this time , but also no longer exists . In 1936 , Works Progress Administration built the Museum of Fine Arts , now called the Arkansas Arts Center , just south of the Tower Building . <eol> The arsenal was listed in the National Register of Historic Places in 1970 . Due to its association with the Camden Expedition of 1864 , the arsenal may be included in the Camden Expedition Sites National Historic Landmark designated in 1994 . <eol> In 1942 , the Tower Building was renovated due to the efforts of the Æsthetic Club , Little Rock philanthropist Frederick W. <unk> , and the Works Progress Administration . It became the new home of The Arkansas Museum of Natural History and Antiquities , which had been located in Little Rock City Hall . The museum remained in the tower building for approximately fifty @-@ five years . The area surrounding the Tower Building had been known as Arsenal Park when the first decommissioned and then later renamed City Park . Due to the efforts of Bernie Babcock , however , the city finally named it MacArthur Park in 1942 in honor of Douglas MacArthur . <eol> In 1997 , the Museum of Science and Natural History merged with the Little Rock Children 's Museum , which had been located in Union Station , to form the Arkansas Museum of Discovery . The new museum was relocated to a historic building in the Little Rock River Market District . The MacArthur Museum of Arkansas Military History opened on May 19 , 2001 in the Tower Building . The new museum 's goal is to educate and inform visitors about the military history of Arkansas , preserve the Tower Building , honor servicemen and <unk> of the United States and commemorate the birthplace of Douglas MacArthur . <eol> <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the fixtures for validation and test - prediction\n",
        "fixtures_pred       = np.load('fixtures/prediction.npz')        # validation\n",
        "fixtures_pred_test  = np.load('fixtures/prediction_test.npz')   # test\n",
        "\n",
        "print(\"Validation shapes    : \", fixtures_pred['inp'].shape, fixtures_pred['out'].shape)\n",
        "print(\"Test shapes          : \", fixtures_pred_test['inp'].shape)\n",
        "print(type(fixtures_pred))\n",
        "print(list(fixtures_pred.keys()))"
      ],
      "metadata": {
        "id": "x5znxQhLSwRC",
        "tags": [],
        "cell_id": "09f3a2efaeef49ef9f4c0b2b9a614cca",
        "execution": {
          "iopub.status.busy": "2022-08-10T14:02:12.884281Z",
          "iopub.status.idle": "2022-08-10T14:02:12.960590Z",
          "iopub.execute_input": "2022-08-10T14:02:12.888156Z",
          "shell.execute_reply": "2022-08-10T14:02:12.958805Z",
          "shell.execute_reply.started": "2022-08-10T14:02:12.888058Z"
        },
        "source_hash": "42e4c03c",
        "execution_start": 1679856368507,
        "execution_millis": 46,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab37a8d-6fd1-4e36-a98f-6de63143171e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation shapes    :  (128, 21) (128,)\n",
            "Test shapes          :  (128, 21)\n",
            "<class 'numpy.lib.npyio.NpzFile'>\n",
            "['inp', 'out']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the fixtures for validation and test - generation\n",
        "fixtures_gen        = np.load('fixtures/generation.npy')        # validation\n",
        "fixtures_gen_test   = np.load('fixtures/generation_test.npy')   # test\n",
        "\n",
        "print(\"Validation Gen Shapes    :\", fixtures_gen.shape)\n",
        "print(\"Test Gen Shapes          :\", fixtures_gen_test.shape)\n",
        "print(type(fixtures_gen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pes7mCr5WdAw",
        "outputId": "cf2d04ea-ece5-4468-b3e4-c822ee53ba29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Gen Shapes    : (32, 21)\n",
            "Test Gen Shapes          : (128, 31)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(5):\n",
        "    print(' '.join(VOCAB[i] for i in fixtures_pred['inp'][idx]))\n",
        "    print(VOCAB[fixtures_pred['out'][idx]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z78yXXCNSCp",
        "outputId": "db81f409-b68d-48eb-d748-5fbafcc04a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> output port of a section will generally not be the same . However , for a mid @-@ series section\n",
            "(\n",
            "<sos> a few from the Heavy <unk> Platoon and one or two from B Company . <unk> , 60 to 70\n",
            "men\n",
            "<sos> <unk> also produced monitors for use on the rivers , the first two of which differed from the ocean @-@\n",
            "going\n",
            "<sos> Head of <unk> . She had been converted from a commercial vessel in New Orleans for river and coastal fighting\n",
            ".\n",
            "<sos> the fight remains controversial , as <unk> tested positive for elevated levels of <unk> prior to his next fight .\n",
            "<unk>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(10):\n",
        "    print(' '.join(VOCAB[i] for i in fixtures_gen[idx]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTWDFOa_5jv8",
        "outputId": "94f8b945-4633-4286-c017-610a3f9af2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> while the group was en route , but only three were ultimately able to attack . None of them were\n",
            "<sos> <unk> , where he remained on loan until 30 June 2010 . <eol> = = = Return to Manchester United\n",
            "<sos> 25 April 2013 , denoting shipments of 500 @,@ 000 copies . <eol> The song became One Direction 's fourth\n",
            "<sos> , and Bruce R. ) one daughter ( Wendy J. <unk> ) and two grandchildren , died in <unk> ,\n",
            "<sos> Warrior were examples of this type . Because their armor was so heavy , they could only carry a single\n",
            "<sos> the embassy at 1 : 49 and landed on Guam at 2 : 23 ; twenty minutes later , Ambassador\n",
            "<sos> <unk> , $ 96 million USD ) . Damage was heaviest in South Korea , notably where it moved ashore\n",
            "<sos> The <unk> were condemned as <unk> by <unk> , who saw the riots as hampering attempts to resolve the situation\n",
            "<sos> by a decision made by the War Office in mid @-@ 1941 , as it was considering the equipment to\n",
            "<sos> Division crossed the <unk> at a number of places and climbed the hills quietly toward the 9th Infantry river line\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom DataLoader"
      ],
      "metadata": {
        "id": "dHjYhXAOzkrP",
        "cell_id": "aec0165a3f1245dfa52a0cb80dba2578",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoaderForLanguageModeling(torch.utils.data.DataLoader): # Inherit from torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "        TODO: Define data loader logic here\n",
        "    \"\"\"\n",
        "    # Implementing a lot of pre processing in __init__() function to allow for\n",
        "    # faster runtime\n",
        "    def __init__(self, dataset, batch_size, seq_len, shuffle = True, drop_last= False):\n",
        "\n",
        "        self.dataset    = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len    = seq_len\n",
        "        self.shuffle    = shuffle\n",
        "        self.drop_last  = drop_last\n",
        "        self.full_len   = len(np.concatenate(self.dataset, axis = 0))\n",
        "\n",
        "        if self.drop_last:\n",
        "            self.n_batches  = ((self.full_len-1)//self.seq_len) // self.batch_size\n",
        "        else:\n",
        "            if ((self.full_len-1)//self.seq_len) % self.batch_size == 0:\n",
        "                self.n_batches  = ((self.full_len-1)//self.seq_len) // self.batch_size\n",
        "            else:\n",
        "                self.n_batches  = (((self.full_len-1)//self.seq_len) // self.batch_size) + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        # What output do you get when you print len(loader)? You get the number of batches\n",
        "        # Your dataset has (579, ) articles and each article has a specified amount of words.\n",
        "        # You concatenate the dataset and then batch parts of it according to the sequence length\n",
        "        # TODO: return the number of batches\n",
        "        # If you are using variable sequence_length, the length might not be fixed\n",
        "        return self.n_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        # Shuffling dataset if shuffle is True\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.dataset)\n",
        "\n",
        "        # Concatenating the dataset into one large text\n",
        "        self.concat_dataset = np.concatenate(self.dataset, axis = 0)\n",
        "\n",
        "        self.inputs, self.targets = [], []\n",
        "\n",
        "        # Computing the final index length until which point we have the complete input, dropping the rest\n",
        "        # Other solution could have been to pad with zeros to save information\n",
        "        end_full_idx = ((len(self.concat_dataset)-1)//self.seq_len) * self.seq_len\n",
        "\n",
        "        # Looping through the concatenated dataset to prepare inputs and targets\n",
        "        for idx in range(0, end_full_idx, self.seq_len):\n",
        "            self.inputs.append(self.concat_dataset[idx: idx + self.seq_len])\n",
        "            self.targets.append(self.concat_dataset[idx+1: idx + 1 + self.seq_len])\n",
        "\n",
        "        # Stacking the inputs and targets\n",
        "        self.inputs = np.row_stack(self.inputs)\n",
        "        self.targets = np.row_stack(self.targets)\n",
        "\n",
        "        # Checking if the input length after stacking can be segmented into clean batches\n",
        "        # If not padding the remaining if drop_last false\n",
        "        if self.inputs.shape[0]%self.batch_size != 0:\n",
        "\n",
        "            if self.drop_last:\n",
        "                self.inputs = self.inputs[0: (self.inputs.shape[0]//self.batch_size) * self.batch_size]\n",
        "                self.targets = self.targets[0: (self.inputs.shape[0]//self.batch_size) * self.batch_size]\n",
        "\n",
        "            else:\n",
        "                pad_width = self.batch_size - (self.inputs.shape[0]%self.batch_size)\n",
        "                self.inputs = np.pad(self.inputs, ((0, pad_width) , (0, 0)), mode = 'constant', constant_values = (0, 0))\n",
        "                self.targets = np.pad(self.targets, ((0, pad_width) , (0, 0)), mode = 'constant', constant_values = (0, 0))\n",
        "\n",
        "\n",
        "        self.num_batches = self.inputs.shape[0] // self.batch_size\n",
        "\n",
        "        for batch_idx in range(self.num_batches):\n",
        "            input_tensors = torch.from_numpy(self.inputs[batch_idx*self.batch_size: (batch_idx+1)*self.batch_size])\n",
        "            target_tensors = torch.from_numpy(self.targets[batch_idx*self.batch_size: (batch_idx+1)*self.batch_size])\n",
        "\n",
        "            yield input_tensors, target_tensors"
      ],
      "metadata": {
        "id": "OZNrJ8XvSwRF",
        "tags": [],
        "cell_id": "b2e63a7f6dec4a3f98588725a72a8ff2",
        "execution": {
          "iopub.status.busy": "2022-08-10T14:02:13.078847Z",
          "iopub.status.idle": "2022-08-10T14:02:13.196189Z",
          "iopub.execute_input": "2022-08-10T14:02:13.079390Z",
          "shell.execute_reply": "2022-08-10T14:02:13.192167Z",
          "shell.execute_reply.started": "2022-08-10T14:02:13.079324Z"
        },
        "source_hash": "a81eaa14",
        "execution_start": 1679856368575,
        "execution_millis": 48,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Some sanity checks\n",
        "\n",
        "dl = DataLoaderForLanguageModeling(\n",
        "    dataset     = dataset,\n",
        "    batch_size  = 32,\n",
        "    seq_len     = 10,\n",
        "    shuffle     = True,\n",
        "    drop_last   = True\n",
        ")\n",
        "\n",
        "inputs, targets = next(iter(dl))\n",
        "print(inputs.shape, targets.shape)\n",
        "\n",
        "for x, y in dl:\n",
        "    print(\"x: \", ' '.join([VOCAB[i] for i in x[0]]))\n",
        "    print(\"y: \", ' '.join([VOCAB[i] for i in y[0]]))\n",
        "    break"
      ],
      "metadata": {
        "id": "fBZSzmy10M9M",
        "cell_id": "773573c8374048d4bcb5a67b905ee2e0",
        "source_hash": "27952b8c",
        "execution_start": 1679856368714,
        "execution_millis": 3,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716bef4b-1c99-4e60-b50e-0dd60f98a960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10]) torch.Size([32, 10])\n",
            "x:  <sos> = Illinois ( Sufjan Stevens album ) = <eol>\n",
            "y:  = Illinois ( Sufjan Stevens album ) = <eol> Illinois\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LanguageModel"
      ],
      "metadata": {
        "id": "WcWU0YlnzmVM",
        "cell_id": "0e75c3c3318d481aa99230d81eb68c13",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here comes the main portion of this HW.\n",
        "# You can do this with a regular LSTM similar to HW3P2.\n",
        "# However, using LSTMCells will make this Language model very similar to the decoder in HW4P2 and we recommend you use that for writing resuable code.\n",
        "\n",
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout): # TODO: Add more parameters if you want\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout            = LockedDropout(dropout)\n",
        "\n",
        "        # For all the layers which you will define, please read the documentation thoroughly before implementation\n",
        "        self.token_embedding    = torch.nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_dim, device = DEVICE)\n",
        "\n",
        "        self.lstm_cells         = torch.nn.Sequential(\n",
        "            *[torch.nn.LSTMCell(input_size = embedding_dim, hidden_size = hidden_dim, device = DEVICE) for i in range(num_layers)],\n",
        "        )\n",
        "\n",
        "        self.token_probability  = torch.nn.Linear(in_features = hidden_dim, out_features = vocab_size, bias = True, device = DEVICE) # TODO: Define the parameters\n",
        "\n",
        "        self.token_probability.weight = self.token_embedding.weight\n",
        "\n",
        "\n",
        "    # rnn_step is recursion through one timestep of RNN\n",
        "    # It takes in embedding and previous hidden_states_list as input and using recursion computes\n",
        "    # the new hidden_state as well as the network_output/embedding output of the last cell\n",
        "    def rnn_step(self, embedding, hidden_states_list):\n",
        "\n",
        "        if hidden_states_list == None:\n",
        "            hidden_states_list      = [None] * len(self.lstm_cells)\n",
        "\n",
        "        for i, lstm_cell in enumerate(self.lstm_cells):\n",
        "            curr_hidden_state       = hidden_states_list[i]\n",
        "            curr_hidden_state       = lstm_cell(embedding, curr_hidden_state)\n",
        "\n",
        "            # Recusrion: Updating the hidden_states_list[i] and cell_states_list[i]\n",
        "            embedding               = curr_hidden_state[0]\n",
        "            hidden_states_list[i]   = curr_hidden_state\n",
        "\n",
        "        return embedding, hidden_states_list\n",
        "\n",
        "    # Given a token sequence x: <sos> t1 t2 t3 t4 ...... tn\n",
        "    # Computing the probability of tn\n",
        "    def predict(self, x):\n",
        "\n",
        "        # x.shape = (batch_size, seq_len/timesteps)\n",
        "\n",
        "        if not torch.is_tensor(x):\n",
        "            x = torch.tensor(x).long().to(DEVICE)\n",
        "\n",
        "        token_probability = 0\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            hidden_states_list  = [None] * len(self.lstm_cells)\n",
        "\n",
        "            for timestep in range(x.shape[1]):\n",
        "\n",
        "                embedding                       = self.token_embedding(x[:, timestep])\n",
        "                lstm_out, hidden_states_list    = self.rnn_step(embedding, hidden_states_list)\n",
        "                token_probability               = self.token_probability(lstm_out)\n",
        "\n",
        "            return token_probability\n",
        "\n",
        "    def generate(self, x, timesteps):\n",
        "        # Refer to section 1.3.2 to understand this function\n",
        "        # Important Note: We do not draw <eos> from the distribution unlike the writeup\n",
        "        if not torch.is_tensor(x):\n",
        "            x = torch.tensor(x).long().to(DEVICE)\n",
        "\n",
        "        # TODO: Pass the input sequence through the model\n",
        "        # Obtain the probability distribution and hidden_states_list of the last timestep\n",
        "\n",
        "        token_prob_dist, hidden_states_list      = self.forward(x)\n",
        "        next_token                               = torch.argmax(token_prob_dist[:, -1, :], dim = 1)\n",
        "\n",
        "        generated_sequence  = []\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            for t in range(timesteps): # Loop through the timesteps\n",
        "                embedding                    = self.token_embedding(next_token)\n",
        "\n",
        "                #   TODO: Pass the next_token and hidden_states_list through the model\n",
        "                #   TODO: You will get 2 outputs. What is the shape of the probability distribution?\n",
        "                lstm_out, hidden_states_list = self.rnn_step(embedding, hidden_states_list)\n",
        "\n",
        "                token_prob_dist              = self.token_probability(lstm_out)\n",
        "\n",
        "                #   TODO: Get the most probable token for the next timestep\n",
        "                next_token                   = torch.argmax(token_prob_dist, dim = 1)\n",
        "\n",
        "                generated_sequence.append(next_token)\n",
        "\n",
        "            generated_sequence = torch.stack(generated_sequence, dim = 1) # keep last timesteps generated words\n",
        "\n",
        "        return generated_sequence\n",
        "\n",
        "    # We are also having a hidden_states_list parameter because you need that in generation\n",
        "    def forward(self, x, hidden_states_list= None): # train model\n",
        "        # x (Batch, Seq_len)\n",
        "        # Note: you dont have to return the sum of log probabilities according to Pseudocode 1 in the writeup\n",
        "        # However, feel free to calculate and print it if you are curious\n",
        "\n",
        "        batch_size, timesteps   = x.shape\n",
        "\n",
        "        token_prob_distribution = [] # list which will contain probability distributions for all timesteps\n",
        "        # Initializing the hidden states\n",
        "        if hidden_states_list == None:\n",
        "            hidden_states_list  = [None] * len(self.lstm_cells)\n",
        "\n",
        "        token_embeddings        = self.token_embedding(x)   # token_embeddings.shape = (batch_size, timesteps, n_emb)\n",
        "        token_embeddings        = self.dropout(token_embeddings.permute(1, 0, 2)).permute((1, 0, 2))\n",
        "\n",
        "        for t in range(timesteps): # LSTMCell is for just 1 timestep. Hence you need to loop through the total timesteps\n",
        "\n",
        "            token_embedding_t           = token_embeddings[:, t, :]\n",
        "            rnn_out, hidden_states_list = self.rnn_step(token_embedding_t, hidden_states_list)\n",
        "            token_prob_dist_t           = self.token_probability(rnn_out)\n",
        "\n",
        "            token_prob_distribution.append(token_prob_dist_t)\n",
        "\n",
        "        token_prob_distribution = torch.stack(token_prob_distribution, dim = 1)\n",
        "\n",
        "        return token_prob_distribution, hidden_states_list"
      ],
      "metadata": {
        "id": "cebwoorWttWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Class"
      ],
      "metadata": {
        "id": "TlWF_bpLznup",
        "cell_id": "8ed5a6ef54f9446fab752b79c70a0216",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlike all the P2s, we are using a Trainer class for this HW.\n",
        "# Many researchers also use classes like this for training. You may have encountered them in your project as well.\n",
        "# You dont have to complete everything in this class, you only need to complete the train function.\n",
        "# However, its good to go through the code and see what it does.\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loader, optimizer, criterion, scheduler, max_epochs= 1, run_id= 'exp'):\n",
        "        \"\"\"\n",
        "            Use this class to train your model\n",
        "        \"\"\"\n",
        "        # feel free to add any other parameters here\n",
        "        self.model      = model\n",
        "        self.loader     = loader\n",
        "        self.optimizer  = optimizer\n",
        "        self.criterion  = criterion\n",
        "        self.scheduler  = scheduler\n",
        "\n",
        "        self.train_losses           = []\n",
        "        self.val_losses             = []\n",
        "        self.predictions            = []\n",
        "        self.predictions_test       = []\n",
        "        self.generated_logits       = []\n",
        "        self.generated              = []\n",
        "        self.generated_logits_test  = []\n",
        "        self.generated_test         = []\n",
        "        self.epochs                 = 0\n",
        "        self.max_epochs             = max_epochs\n",
        "        self.run_id                 = run_id\n",
        "\n",
        "\n",
        "        self.scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "    def calculate_loss(self, out, target):\n",
        "        # output: (B, T, Vocab_size) - probability distributions\n",
        "        # target: (B, T)\n",
        "        # Read the documentation of CrossEntropyLoss and try to understand how it takes inputs\n",
        "\n",
        "        # Tip: If your target is of shape (B, T) it means that you have B batches with T words.\n",
        "        # Tip: What is the total number of words in this batch?\n",
        "        # Tip: Crossentropy calculates the loss between a label and its probability distribution.\n",
        "\n",
        "        out     = out.permute((0, 2, 1))\n",
        "        targets = target\n",
        "\n",
        "        loss    = self.criterion(out, targets)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        self.model.train() # set to training mode\n",
        "        self.model.to(DEVICE)\n",
        "        epoch_loss  = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch_num, (inputs, targets) in enumerate(tqdm(self.loader)):\n",
        "            # Setting the gradients to zero after every batch\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Putting the inputs and targets on device\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            # Implementing mixed precision\n",
        "            with torch.cuda.amp.autocast():\n",
        "\n",
        "                token_prob_distribution, hidden_states_list = self.model(inputs)\n",
        "                loss = self.calculate_loss(token_prob_distribution, targets)\n",
        "\n",
        "            # Tip: Mixed precision training\n",
        "            # For loss calculation, use the calculate_loss function. You need to complete it before using.\n",
        "\n",
        "            loss = loss\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            self.scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "            self.scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "            self.scaler.update() # This is something added just for FP16\n",
        "\n",
        "        self.scheduler.step()\n",
        "\n",
        "        epoch_loss = epoch_loss / (batch_num + 1)\n",
        "        self.epochs += 1\n",
        "        print('[TRAIN] \\tEpoch [%d/%d] \\tLoss: %.4f \\tLr: %.6f'\n",
        "                      % (self.epochs, self.max_epochs, epoch_loss, self.optimizer.param_groups[0]['lr']))\n",
        "        self.train_losses.append(epoch_loss)\n",
        "\n",
        "\n",
        "\n",
        "    def test(self): # Don't change this function\n",
        "\n",
        "        self.model.eval() # set to eval mode\n",
        "        predictions     = model.predict(fixtures_pred['inp']).detach().cpu().numpy() # get predictions\n",
        "        self.predictions.append(predictions)\n",
        "\n",
        "        generated_logits        = model.generate(fixtures_gen, 10).detach().cpu().numpy() # generated predictions for 10 words\n",
        "        generated_logits_test   = model.generate(fixtures_gen_test, 10).detach().cpu().numpy()\n",
        "\n",
        "        nll             = test_prediction(predictions, fixtures_pred['out'])\n",
        "        generated       = test_generation(fixtures_gen, generated_logits, VOCAB)\n",
        "        generated_test  = test_generation(fixtures_gen_test, generated_logits_test, VOCAB)\n",
        "        self.val_losses.append(nll)\n",
        "\n",
        "        self.generated.append(generated)\n",
        "        self.generated_test.append(generated_test)\n",
        "        self.generated_logits.append(generated_logits)\n",
        "        self.generated_logits_test.append(generated_logits_test)\n",
        "\n",
        "        # generate predictions for test data\n",
        "        predictions_test = model.predict(fixtures_pred_test['inp']).detach().cpu().numpy() # get predictions\n",
        "        self.predictions_test.append(predictions_test)\n",
        "\n",
        "        print('[VAL] \\tEpoch [%d/%d] \\tLoss: %.4f'\n",
        "                      % (self.epochs, self.max_epochs, nll))\n",
        "        return nll\n",
        "\n",
        "\n",
        "    def save(self): # Don't change this function\n",
        "\n",
        "        model_path = os.path.join('hw4/experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
        "        torch.save({'state_dict': self.model.state_dict()}, model_path)\n",
        "        np.save(os.path.join('hw4/experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
        "        np.save(os.path.join('hw4/experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
        "        np.save(os.path.join('hw4/experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
        "        np.save(os.path.join('hw4/experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
        "\n",
        "        with open(os.path.join('hw4/experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
        "            fw.write(self.generated[-1])\n",
        "\n",
        "        with open(os.path.join('hw4/experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
        "            fw.write(self.generated_test[-1])"
      ],
      "metadata": {
        "id": "kIvZOIfjSwRK",
        "tags": [],
        "cell_id": "8ea986fc372643389d1ab4c445659e9d",
        "execution": {
          "iopub.status.busy": "2022-08-10T14:02:13.440281Z",
          "iopub.status.idle": "2022-08-10T14:02:13.644455Z",
          "iopub.execute_input": "2022-08-10T14:02:13.440820Z",
          "shell.execute_reply": "2022-08-10T14:02:13.642614Z",
          "shell.execute_reply.started": "2022-08-10T14:02:13.440752Z"
        },
        "source_hash": "451a140f",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment setup"
      ],
      "metadata": {
        "id": "E6NKG0j8zsv-",
        "cell_id": "db5de3ac0c6e48ca9cff0cd79bef7ae8",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: define other hyperparameters here\n",
        "\n",
        "configs = dict(\n",
        "    batch_size  = 128,\n",
        "    num_epochs  = 20,\n",
        "    emb_dim     = 500,\n",
        "    hid_dim     = 500,\n",
        "    init_lr     = 1e-3,\n",
        "    seq_len     = 10,\n",
        "    num_layers  = 5,\n",
        "    dropout     = 0.5\n",
        ")"
      ],
      "metadata": {
        "id": "TiUrjbEjSwRQ",
        "tags": [],
        "cell_id": "7fc44ee4771a42f996d0a00d35529fb6",
        "execution": {
          "iopub.status.busy": "2022-08-10T14:02:13.850633Z",
          "iopub.status.idle": "2022-08-10T14:02:13.927227Z",
          "iopub.execute_input": "2022-08-10T14:02:13.852171Z",
          "shell.execute_reply": "2022-08-10T14:02:13.924500Z",
          "shell.execute_reply.started": "2022-08-10T14:02:13.852093Z"
        },
        "source_hash": "f7524436",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model       = LanguageModel(vocab_size = VOCAB.shape[0], embedding_dim = configs['emb_dim'], hidden_dim = configs['hid_dim'],\n",
        "                            num_layers = configs['num_layers'], dropout = configs['dropout'])\n",
        "\n",
        "loader      = DataLoaderForLanguageModeling(\n",
        "    dataset     = dataset,\n",
        "    batch_size  = configs['batch_size'],\n",
        "    seq_len     = configs['seq_len'],\n",
        "    shuffle     = True,\n",
        "    drop_last   = True)\n",
        "\n",
        "criterion   = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer   = torch.optim.AdamW(model.parameters(), lr = configs['init_lr'], weight_decay = configs['init_lr']/100)\n",
        "\n",
        "scheduler   = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = configs['num_epochs'], eta_min = configs['init_lr']/20, verbose = True)\n",
        "\n",
        "\n",
        "print(model)\n",
        "torchsummaryX.summary(model, x = inputs.to(DEVICE))"
      ],
      "metadata": {
        "id": "DbHH6zXTSwRa",
        "tags": [],
        "cell_id": "4aaccf1c32fa480a9a15e8bb8bc4d9e4",
        "execution": {
          "iopub.status.busy": "2022-08-10T14:02:14.109778Z",
          "iopub.status.idle": "2022-08-10T14:02:14.929087Z",
          "iopub.execute_input": "2022-08-10T14:02:14.110787Z",
          "shell.execute_reply": "2022-08-10T14:02:14.925078Z",
          "shell.execute_reply.started": "2022-08-10T14:02:14.110707Z"
        },
        "source_hash": "2acff566",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bb2ba47-6e05-4a90-95dd-d8b831c3dbd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n",
            "LanguageModel(\n",
            "  (dropout): LockedDropout(p=0.5)\n",
            "  (token_embedding): Embedding(33280, 500)\n",
            "  (lstm_cells): Sequential(\n",
            "    (0): LSTMCell(500, 500)\n",
            "    (1): LSTMCell(500, 500)\n",
            "    (2): LSTMCell(500, 500)\n",
            "    (3): LSTMCell(500, 500)\n",
            "    (4): LSTMCell(500, 500)\n",
            "  )\n",
            "  (token_probability): Linear(in_features=500, out_features=33280, bias=True)\n",
            ")\n",
            "=============================================================================\n",
            "                          Kernel Shape   Output Shape     Params Mult-Adds\n",
            "Layer                                                                     \n",
            "0_token_embedding         [500, 33280]  [32, 10, 500]     16.64M    16.64M\n",
            "1_dropout                            -  [10, 32, 500]          -         -\n",
            "2_lstm_cells.LSTMCell_0              -      [32, 500]     2.004M      2.0M\n",
            "3_lstm_cells.LSTMCell_1              -      [32, 500]     2.004M      2.0M\n",
            "4_lstm_cells.LSTMCell_2              -      [32, 500]     2.004M      2.0M\n",
            "5_lstm_cells.LSTMCell_3              -      [32, 500]     2.004M      2.0M\n",
            "6_lstm_cells.LSTMCell_4              -      [32, 500]     2.004M      2.0M\n",
            "7_token_probability       [500, 33280]    [32, 33280]  16.67328M    16.64M\n",
            "8_lstm_cells.LSTMCell_0              -      [32, 500]          -      2.0M\n",
            "9_lstm_cells.LSTMCell_1              -      [32, 500]          -      2.0M\n",
            "10_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "11_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "12_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "13_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "14_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "15_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "16_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "17_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "18_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "19_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "20_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "21_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "22_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "23_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "24_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "25_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "26_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "27_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "28_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "29_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "30_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "31_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "32_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "33_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "34_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "35_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "36_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "37_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "38_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "39_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "40_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "41_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "42_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "43_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "44_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "45_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "46_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "47_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "48_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "49_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "50_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "51_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "52_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "53_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "54_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "55_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "56_lstm_cells.LSTMCell_0             -      [32, 500]          -      2.0M\n",
            "57_lstm_cells.LSTMCell_1             -      [32, 500]          -      2.0M\n",
            "58_lstm_cells.LSTMCell_2             -      [32, 500]          -      2.0M\n",
            "59_lstm_cells.LSTMCell_3             -      [32, 500]          -      2.0M\n",
            "60_lstm_cells.LSTMCell_4             -      [32, 500]          -      2.0M\n",
            "61_token_probability      [500, 33280]    [32, 33280]          -    16.64M\n",
            "-----------------------------------------------------------------------------\n",
            "                         Totals\n",
            "Total params          43.33328M\n",
            "Trainable params      43.33328M\n",
            "Non-trainable params        0.0\n",
            "Mult-Adds               283.04M\n",
            "=============================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Kernel Shape   Output Shape      Params   Mult-Adds\n",
              "Layer                                                                        \n",
              "0_token_embedding         [500, 33280]  [32, 10, 500]  16640000.0  16640000.0\n",
              "1_dropout                            -  [10, 32, 500]         NaN         NaN\n",
              "2_lstm_cells.LSTMCell_0              -      [32, 500]   2004000.0   2000000.0\n",
              "3_lstm_cells.LSTMCell_1              -      [32, 500]   2004000.0   2000000.0\n",
              "4_lstm_cells.LSTMCell_2              -      [32, 500]   2004000.0   2000000.0\n",
              "...                                ...            ...         ...         ...\n",
              "57_lstm_cells.LSTMCell_1             -      [32, 500]         NaN   2000000.0\n",
              "58_lstm_cells.LSTMCell_2             -      [32, 500]         NaN   2000000.0\n",
              "59_lstm_cells.LSTMCell_3             -      [32, 500]         NaN   2000000.0\n",
              "60_lstm_cells.LSTMCell_4             -      [32, 500]         NaN   2000000.0\n",
              "61_token_probability      [500, 33280]    [32, 33280]         NaN  16640000.0\n",
              "\n",
              "[62 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb526bd7-12d6-4292-b14d-80c8889d24bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_token_embedding</th>\n",
              "      <td>[500, 33280]</td>\n",
              "      <td>[32, 10, 500]</td>\n",
              "      <td>16640000.0</td>\n",
              "      <td>16640000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_dropout</th>\n",
              "      <td>-</td>\n",
              "      <td>[10, 32, 500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm_cells.LSTMCell_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 500]</td>\n",
              "      <td>2004000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_lstm_cells.LSTMCell_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 500]</td>\n",
              "      <td>2004000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_lstm_cells.LSTMCell_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 500]</td>\n",
              "      <td>2004000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57_lstm_cells.LSTMCell_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58_lstm_cells.LSTMCell_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59_lstm_cells.LSTMCell_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60_lstm_cells.LSTMCell_4</th>\n",
              "      <td>-</td>\n",
              "      <td>[32, 500]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61_token_probability</th>\n",
              "      <td>[500, 33280]</td>\n",
              "      <td>[32, 33280]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16640000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb526bd7-12d6-4292-b14d-80c8889d24bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb526bd7-12d6-4292-b14d-80c8889d24bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb526bd7-12d6-4292-b14d-80c8889d24bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Dont change this cell\n",
        "\n",
        "run_id = str(int(time.time()))\n",
        "if not os.path.exists('./hw4/experiments'):\n",
        "    os.mkdir('./hw4/experiments')\n",
        "os.mkdir('./hw4/experiments/%s' % run_id)\n",
        "print(\"Saving models, predictions, and generated words to ./hw4/experiments/%s\" % run_id)\n",
        "\n",
        "# The object of the Trainer class takes in everything\n",
        "trainer = Trainer(\n",
        "    model       = model,\n",
        "    loader      = loader,\n",
        "\n",
        "    optimizer   = optimizer,\n",
        "    criterion   = criterion,\n",
        "    scheduler   = scheduler,\n",
        "\n",
        "    max_epochs  = configs['num_epochs'],\n",
        "    run_id      = run_id\n",
        ")"
      ],
      "metadata": {
        "id": "2HCVG5YISwRW",
        "tags": [],
        "cell_id": "aaff53cf948e44b7b9bd49cbcad0ac58",
        "execution": {
          "iopub.status.busy": "2022-08-10T14:02:13.930204Z",
          "iopub.status.idle": "2022-08-10T14:02:14.107883Z",
          "iopub.execute_input": "2022-08-10T14:02:13.931258Z",
          "shell.execute_reply": "2022-08-10T14:02:14.105987Z",
          "shell.execute_reply.started": "2022-08-10T14:02:13.931185Z"
        },
        "source_hash": "c9f4594a",
        "deepnote_to_be_reexecuted": true,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82533d14-b8ac-48bd-e263-8e8af9cee6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models, predictions, and generated words to ./hw4/experiments/1682524312\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhzC-G6yzEGK",
        "outputId": "bc191df8-e349-445a-b8e9-62c7471ac2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    initial_lr: 0.001\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 1e-05\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the experiments loop.\n",
        "# Each epoch wont take more than 2-3min. If its taking more time, it might be due to (but not limited to) the following:\n",
        "#   * You might be overlapping batches\n",
        "#       Eg. Input: \"I had biryani for lunch today\" and sequence length = 3,\n",
        "#           --> \"I had biryani\", \"for lunch today\" are ideal examples for inputs\n",
        "#           --> \"I had biryani\", \"had biryani for\", \"biryani for lunch\", ... is just redundant info :')\n",
        "#   * Your length calculation in the dataloader might be wrong\n",
        "# If you haven't had biryani, try it :D\n",
        "\n",
        "%%time\n",
        "best_nll = 1e30\n",
        "for epoch in range(configs['num_epochs']):\n",
        "    trainer.train()\n",
        "    nll = trainer.test()\n",
        "    if nll < best_nll:\n",
        "        best_nll = nll\n",
        "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch+1)+\" with NLL: \"+ str(best_nll))\n",
        "        trainer.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "99045c03400b47a6a5a3c304002f5c82",
            "54f520840a314e1c808476367dcc94ca",
            "fa535d4d82654da0b3b42a45c9d7b171",
            "8239fa2d6df442a3b06d390ae66de2f8",
            "22839d08b20d496c919203463543f089",
            "3c9df0b9bdb64f8083384efca7cc9e0a",
            "299e097736744d809538deeb18f7944d",
            "4b8ea684b5dd4121befc846017f91a8c",
            "61ef5f40e88544f1801a5b8875a3f4b9",
            "4db2a5aa11eb48d1899c958473d8a74f",
            "642e88b9acaa48bf88b3ceea4eb037a9",
            "6a0d5887dd554920a2f3273b83616fad",
            "d86a33d36baa4d2d9421bbcf429d69bc",
            "d6f1998c02a949ddbfb7e53d1dd11c7b",
            "fa4ac134584c483c8102f741d532909f",
            "17bd53288cdb4f47b0c0276c1e0d9f60",
            "40f56d27747540adb1c4978e299bb532",
            "60ac31e0e01344a19ac6f50d1914a1e1",
            "39c51e39bb434535912a24ebde243e1a",
            "e4d121608f774aa98c6fdbd855e0e077",
            "c5f736afe63849a8bced171512247572",
            "83e09ed874974e8cb6f60c515370c6d6",
            "85287424de2f49079bccc09dae59334e",
            "1cf3c5054f07462e891d82022b9d0ebe",
            "637435dccaf542ca843c08498f2758a5",
            "7c63ae44e0554122b6d5c17a4716d1df",
            "f1bc8dd1a78a472d91a870f4bf47ed0f",
            "2d03602ae9534bb397faa0d674f20ec7",
            "3c93ee1a23b147898c36b840769c4c80",
            "14a46f5520aa4dc681fbac1d51890864",
            "d84c8a37552c4d6787bd7e9d00ea4a6d",
            "30b3eb2a4d634e018e032ba8e552c278",
            "1583ff4c285a438d9516dbba2f438cb7",
            "53b7ee5a209241f3a286484fe7c786bf",
            "4061aad399e7404a9a5347044f7a951d",
            "5c44c8e9c400413688f29928aa9e5f54",
            "a8633ae0aaaf43a6863d5f6efed6ccfa",
            "655ee63387eb4c8986b6a57fb3c339d1",
            "a9000150c3ef43f48701b592b3291ca0",
            "a9e303393a3c445692c1207e4a33718a",
            "4b779d891ee7435a8a37d712aa930d9d",
            "9c5e85eee2094547987b27159ffbac49",
            "0a1d7ada59784e8081060db38e199683",
            "e5832b19643149fbba025764d56deeae",
            "9a689e4ff28c461390f1cc1ab85ad9f3",
            "e1d071a69c1a4f78b2963d921d7dcd56",
            "0c759ebe455d434dbafb26e138f43610",
            "6c26c79f6c0c44f59ec35657d80b9c75",
            "3cb94f80713741d99a92d67a58875304",
            "21c63e0c11e84cd0bf83a74bbb033b5e",
            "688b7f18063540db94c5f87c9c6421b1",
            "c28441ab2d09457b89e0f7082abc1646",
            "dbd97b974e2f47b8bd174202405afe31",
            "3040d4e40d424796bf560edc303086f2",
            "9854e0270b99413787cf75c805eba384",
            "7820443076844300b7bf09094d6eeba1",
            "45325119b1154214a40fca24ad9fcfbe",
            "317448e1f1194e47bf42e3ae655e783a",
            "a5a0723315294010a7e60dcfb3019dda",
            "9671acbc67df45ab95196c241ce3c630"
          ]
        },
        "id": "ct3tp73sP9yv",
        "outputId": "d2b49383-3218-42b0-f769-fb5f811e019c"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99045c03400b47a6a5a3c304002f5c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 9.9415e-04.\n",
            "[TRAIN] \tEpoch [1/20] \tLoss: 6.6626 \tLr: 0.000994\n",
            "[VAL] \tEpoch [1/20] \tLoss: 5.4027\n",
            "Saving model, predictions and generated output for epoch 1 with NLL: 5.4027042\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a0d5887dd554920a2f3273b83616fad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 9.7675e-04.\n",
            "[TRAIN] \tEpoch [2/20] \tLoss: 6.0259 \tLr: 0.000977\n",
            "[VAL] \tEpoch [2/20] \tLoss: 4.9867\n",
            "Saving model, predictions and generated output for epoch 2 with NLL: 4.9866877\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85287424de2f49079bccc09dae59334e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 9.4823e-04.\n",
            "[TRAIN] \tEpoch [3/20] \tLoss: 5.7891 \tLr: 0.000948\n",
            "[VAL] \tEpoch [3/20] \tLoss: 4.8282\n",
            "Saving model, predictions and generated output for epoch 3 with NLL: 4.828168\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53b7ee5a209241f3a286484fe7c786bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 9.0928e-04.\n",
            "[TRAIN] \tEpoch [4/20] \tLoss: 5.6280 \tLr: 0.000909\n",
            "[VAL] \tEpoch [4/20] \tLoss: 4.7534\n",
            "Saving model, predictions and generated output for epoch 4 with NLL: 4.753426\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4061aad399e7404a9a5347044f7a951d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 8.6088e-04.\n",
            "[TRAIN] \tEpoch [5/20] \tLoss: 5.4989 \tLr: 0.000861\n",
            "[VAL] \tEpoch [5/20] \tLoss: 4.6369\n",
            "Saving model, predictions and generated output for epoch 5 with NLL: 4.6368895\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c44c8e9c400413688f29928aa9e5f54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 8.0420e-04.\n",
            "[TRAIN] \tEpoch [6/20] \tLoss: 5.3870 \tLr: 0.000804\n",
            "[VAL] \tEpoch [6/20] \tLoss: 4.6093\n",
            "Saving model, predictions and generated output for epoch 6 with NLL: 4.6092525\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8633ae0aaaf43a6863d5f6efed6ccfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 7.4065e-04.\n",
            "[TRAIN] \tEpoch [7/20] \tLoss: 5.2929 \tLr: 0.000741\n",
            "[VAL] \tEpoch [7/20] \tLoss: 4.5885\n",
            "Saving model, predictions and generated output for epoch 7 with NLL: 4.588518\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "655ee63387eb4c8986b6a57fb3c339d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 6.7178e-04.\n",
            "[TRAIN] \tEpoch [8/20] \tLoss: 5.2085 \tLr: 0.000672\n",
            "[VAL] \tEpoch [8/20] \tLoss: 4.4958\n",
            "Saving model, predictions and generated output for epoch 8 with NLL: 4.4958234\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9000150c3ef43f48701b592b3291ca0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 5.9931e-04.\n",
            "[TRAIN] \tEpoch [9/20] \tLoss: 5.1285 \tLr: 0.000599\n",
            "[VAL] \tEpoch [9/20] \tLoss: 4.4707\n",
            "Saving model, predictions and generated output for epoch 9 with NLL: 4.4707384\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9e303393a3c445692c1207e4a33718a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 5.2500e-04.\n",
            "[TRAIN] \tEpoch [10/20] \tLoss: 5.0585 \tLr: 0.000525\n",
            "[VAL] \tEpoch [10/20] \tLoss: 4.4223\n",
            "Saving model, predictions and generated output for epoch 10 with NLL: 4.4223127\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b779d891ee7435a8a37d712aa930d9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 4.5069e-04.\n",
            "[TRAIN] \tEpoch [11/20] \tLoss: 4.9893 \tLr: 0.000451\n",
            "[VAL] \tEpoch [11/20] \tLoss: 4.4182\n",
            "Saving model, predictions and generated output for epoch 11 with NLL: 4.418227\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5e85eee2094547987b27159ffbac49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 3.7822e-04.\n",
            "[TRAIN] \tEpoch [12/20] \tLoss: 4.9330 \tLr: 0.000378\n",
            "[VAL] \tEpoch [12/20] \tLoss: 4.4101\n",
            "Saving model, predictions and generated output for epoch 12 with NLL: 4.4101353\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a1d7ada59784e8081060db38e199683",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 3.0935e-04.\n",
            "[TRAIN] \tEpoch [13/20] \tLoss: 4.8772 \tLr: 0.000309\n",
            "[VAL] \tEpoch [13/20] \tLoss: 4.4874\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5832b19643149fbba025764d56deeae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 2.4580e-04.\n",
            "[TRAIN] \tEpoch [14/20] \tLoss: 4.8259 \tLr: 0.000246\n",
            "[VAL] \tEpoch [14/20] \tLoss: 4.4643\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a689e4ff28c461390f1cc1ab85ad9f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.8912e-04.\n",
            "[TRAIN] \tEpoch [15/20] \tLoss: 4.7796 \tLr: 0.000189\n",
            "[VAL] \tEpoch [15/20] \tLoss: 4.4794\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1d071a69c1a4f78b2963d921d7dcd56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.4072e-04.\n",
            "[TRAIN] \tEpoch [16/20] \tLoss: 4.7438 \tLr: 0.000141\n",
            "[VAL] \tEpoch [16/20] \tLoss: 4.4785\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c759ebe455d434dbafb26e138f43610",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 1.0177e-04.\n",
            "[TRAIN] \tEpoch [17/20] \tLoss: 4.7117 \tLr: 0.000102\n",
            "[VAL] \tEpoch [17/20] \tLoss: 4.5054\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c26c79f6c0c44f59ec35657d80b9c75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 7.3248e-05.\n",
            "[TRAIN] \tEpoch [18/20] \tLoss: 4.6855 \tLr: 0.000073\n",
            "[VAL] \tEpoch [18/20] \tLoss: 4.5160\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5a0723315294010a7e60dcfb3019dda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 5.5848e-05.\n",
            "[TRAIN] \tEpoch [19/20] \tLoss: 4.6621 \tLr: 0.000056\n",
            "[VAL] \tEpoch [19/20] \tLoss: 4.5042\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9671acbc67df45ab95196c241ce3c630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1622 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "[TRAIN] \tEpoch [20/20] \tLoss: 4.6486 \tLr: 0.000050\n",
            "[VAL] \tEpoch [20/20] \tLoss: 4.5232\n",
            "CPU times: user 37min 42s, sys: 12 s, total: 37min 54s\n",
            "Wall time: 37min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
        "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('NLL')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lsOHqEu7P9wI",
        "outputId": "d92e007b-7e20-4313-f0c8-052b9bc2b620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Generate the handin to submit to autolab\n",
        "!make runid=1682524312 epoch=12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl39orIXP9tg",
        "outputId": "40a6335d-07ee-4f97-cd26-bb542d190bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp hw4/experiments/1682524312/predictions-test-12.npy predictions.npy\n",
            "cp hw4/experiments/1682524312/generated-12.txt generated.txt\n",
            "cp hw4/experiments/1682524312/generated_logits-test-12.npy generated_logits.npy\n",
            "cp hw4/hw4p1.ipynb training.ipynb\n",
            "tar -cvf handin.tar training.ipynb predictions.npy generated.txt generated_logits.npy\n",
            "training.ipynb\n",
            "predictions.npy\n",
            "generated.txt\n",
            "generated_logits.npy\n",
            "rm -f generated.txt predictions.npy training.ipynb generated_logits.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp hw4/experiments/1682524312/predictions-test-12.npy predictions.npy\n",
        "!cp hw4/experiments/1682524312/generated-12.txt generated.txt\n",
        "!cp hw4/experiments/1682524312/generated_logits-test-12.npy generated_logits.npy\n",
        "!cp hw4/hw4p1.ipynb training.ipynb\n",
        "!tar -cvf handin.tar training.ipynb predictions.npy generated.txt generated_logits.npy\n",
        "\n",
        "!rm -f generated.txt predictions.npy training.ipynb generated_logits.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uox3r4C1P9rT",
        "outputId": "2b2c05a4-d226-47ab-e999-6a0baf12ebca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training.ipynb\n",
            "predictions.npy\n",
            "generated.txt\n",
            "generated_logits.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /bin/wandbRuns.zip /content/wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXpPxvun8zq1",
        "outputId": "644a454d-98e8-4488-cffb-04181bbb20f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/wandb/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/run-7m4v6v6i.wandb (deflated 79%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/files/wandb-metadata.json (deflated 46%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/files/output.log (deflated 36%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/logs/debug-internal.log (deflated 92%)\n",
            "  adding: content/wandb/run-20230407_080735-7m4v6v6i/logs/debug.log (deflated 79%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/run-puu49x5i.wandb (deflated 84%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/files/output.log (deflated 93%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/logs/debug-internal.log (deflated 93%)\n",
            "  adding: content/wandb/run-20230407_063756-puu49x5i/logs/debug.log (deflated 88%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/run-rm6ign7p.wandb (deflated 64%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/files/output.log (deflated 24%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/logs/debug-internal.log (deflated 90%)\n",
            "  adding: content/wandb/run-20230407_072615-rm6ign7p/logs/debug.log (deflated 79%)\n",
            "  adding: content/wandb/latest-run/ (stored 0%)\n",
            "  adding: content/wandb/latest-run/files/ (stored 0%)\n",
            "  adding: content/wandb/latest-run/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/latest-run/files/Epoch_checkpoint_v2.pth (deflated 8%)\n",
            "  adding: content/wandb/latest-run/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/latest-run/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/latest-run/files/output.log (deflated 92%)\n",
            "  adding: content/wandb/latest-run/files/Best_checkpoint_v2.pth (deflated 8%)\n",
            "  adding: content/wandb/latest-run/files/wandb-summary.json (deflated 34%)\n",
            "  adding: content/wandb/latest-run/tmp/ (stored 0%)\n",
            "  adding: content/wandb/latest-run/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/latest-run/run-t0nqwu5s.wandb (deflated 85%)\n",
            "  adding: content/wandb/latest-run/logs/ (stored 0%)\n",
            "  adding: content/wandb/latest-run/logs/debug-internal.log (deflated 96%)\n",
            "  adding: content/wandb/latest-run/logs/debug.log (deflated 86%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/run-hdnpx3hs.wandb (deflated 81%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/files/output.log (deflated 42%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/logs/debug-internal.log (deflated 93%)\n",
            "  adding: content/wandb/run-20230407_081724-hdnpx3hs/logs/debug.log (deflated 79%)\n",
            "  adding: content/wandb/debug-cli.root.log (stored 0%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/Epoch_checkpoint_v2.pth (deflated 8%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/output.log (deflated 92%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/Best_checkpoint_v2.pth (deflated 8%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/files/wandb-summary.json (deflated 34%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/run-t0nqwu5s.wandb (deflated 85%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/logs/debug-internal.log (deflated 96%)\n",
            "  adding: content/wandb/run-20230407_083033-t0nqwu5s/logs/debug.log (deflated 86%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/files/output.log (deflated 30%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/run-32yfqki6.wandb (deflated 63%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/logs/debug-internal.log (deflated 89%)\n",
            "  adding: content/wandb/run-20230407_062831-32yfqki6/logs/debug.log (deflated 79%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/files/output.log (deflated 86%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/logs/debug-internal.log (deflated 92%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/logs/debug.log (deflated 83%)\n",
            "  adding: content/wandb/run-20230407_070336-eag45ue5/run-eag45ue5.wandb (deflated 77%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/files/output.log (deflated 54%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/run-ig3wmdgn.wandb (deflated 82%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/logs/debug-internal.log (deflated 94%)\n",
            "  adding: content/wandb/run-20230407_073243-ig3wmdgn/logs/debug.log (deflated 79%)\n",
            "  adding: content/wandb/debug-internal.log (deflated 96%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/files/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/files/config.yaml (deflated 59%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/files/wandb-metadata.json (deflated 45%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/files/requirements.txt (deflated 55%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/files/output.log (deflated 86%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/files/wandb-summary.json (stored 0%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/tmp/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/tmp/code/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/run-y7kezatb.wandb (deflated 77%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/logs/ (stored 0%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/logs/debug-internal.log (deflated 93%)\n",
            "  adding: content/wandb/run-20230407_071032-y7kezatb/logs/debug.log (deflated 83%)\n",
            "  adding: content/wandb/debug.log (deflated 86%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "1ub9mCnn9hbt",
        "outputId": "c431b93d-fc4c-49a1-c7f0-6a566fb8bf93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not contain a space.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m   metadata_server_addr = _os.environ[\n\u001b[0m\u001b[1;32m    121\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'TBE_EPHEM_CREDS_ADDR'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!google-drive-ocamlfuse /content/Drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9JhLEsLFJ_K",
        "outputId": "406b233c-472d-4d24-9d25-5fdbb34edbd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: google-drive-ocamlfuse: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3-pip\n",
        "!sudo pip3 install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ26da0G_J5X",
        "outputId": "10e86ca6-8dc0-4a4b-94a5-35909360101f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connecting to clou\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connecting to clou\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:12 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 135 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.8 [231 kB]\n",
            "Fetched 2,389 kB in 1s (3,212 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 128221 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.8/dist-packages (2.16.1)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.8/dist-packages (0.4.6)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.8/dist-packages (0.1.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.8/dist-packages (2.70.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-httplib2) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client) (2.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.58.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.19.6)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-0Pt2diA6_w",
        "outputId": "2c52fd4d-7a39-4ffb-c095-46a52e052462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Connecting to security.ub\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [76.4 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [995 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,334 kB]\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,341 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,644 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,150 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
            "Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease [24.3 kB]\n",
            "Hit:23 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:24 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,170 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,035 kB]\n",
            "Get:27 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,561 kB]\n",
            "Get:28 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,208 kB]\n",
            "Get:29 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Get:30 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal/main amd64 Packages [46.7 kB]\n",
            "Fetched 18.1 MB in 5s (3,554 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y google-drive-ocamlfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoUOp-YSD-ED",
        "outputId": "041d81d1-f95d-4b01-f8bb-dde4824ff7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package google-drive-ocamlfuse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository universe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Vsm47GEA2a",
        "outputId": "b47c10cd-08e8-43d0-d2d1-b056cc27f898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'universe' distribution component is already enabled for all sources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5_gZcjahERnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "EB2bOV3bzYLR",
        "INh9p3v3zbF_",
        "u-R794-0zc9V"
      ],
      "gpuType": "T4"
    },
    "deepnote": {},
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    },
    "deepnote_notebook_id": "989a3c3836794109ac641230122845a3",
    "deepnote_execution_queue": [],
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "99045c03400b47a6a5a3c304002f5c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54f520840a314e1c808476367dcc94ca",
              "IPY_MODEL_fa535d4d82654da0b3b42a45c9d7b171",
              "IPY_MODEL_8239fa2d6df442a3b06d390ae66de2f8"
            ],
            "layout": "IPY_MODEL_22839d08b20d496c919203463543f089"
          }
        },
        "54f520840a314e1c808476367dcc94ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c9df0b9bdb64f8083384efca7cc9e0a",
            "placeholder": "​",
            "style": "IPY_MODEL_299e097736744d809538deeb18f7944d",
            "value": "100%"
          }
        },
        "fa535d4d82654da0b3b42a45c9d7b171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b8ea684b5dd4121befc846017f91a8c",
            "max": 1622,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61ef5f40e88544f1801a5b8875a3f4b9",
            "value": 1622
          }
        },
        "8239fa2d6df442a3b06d390ae66de2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db2a5aa11eb48d1899c958473d8a74f",
            "placeholder": "​",
            "style": "IPY_MODEL_642e88b9acaa48bf88b3ceea4eb037a9",
            "value": " 1622/1622 [01:52&lt;00:00, 14.52it/s]"
          }
        },
        "22839d08b20d496c919203463543f089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9df0b9bdb64f8083384efca7cc9e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299e097736744d809538deeb18f7944d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b8ea684b5dd4121befc846017f91a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ef5f40e88544f1801a5b8875a3f4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4db2a5aa11eb48d1899c958473d8a74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642e88b9acaa48bf88b3ceea4eb037a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a0d5887dd554920a2f3273b83616fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d86a33d36baa4d2d9421bbcf429d69bc",
              "IPY_MODEL_d6f1998c02a949ddbfb7e53d1dd11c7b",
              "IPY_MODEL_fa4ac134584c483c8102f741d532909f"
            ],
            "layout": "IPY_MODEL_17bd53288cdb4f47b0c0276c1e0d9f60"
          }
        },
        "d86a33d36baa4d2d9421bbcf429d69bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f56d27747540adb1c4978e299bb532",
            "placeholder": "​",
            "style": "IPY_MODEL_60ac31e0e01344a19ac6f50d1914a1e1",
            "value": "100%"
          }
        },
        "d6f1998c02a949ddbfb7e53d1dd11c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c51e39bb434535912a24ebde243e1a",
            "max": 1622,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4d121608f774aa98c6fdbd855e0e077",
            "value": 1622
          }
        },
        "fa4ac134584c483c8102f741d532909f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f736afe63849a8bced171512247572",
            "placeholder": "​",
            "style": "IPY_MODEL_83e09ed874974e8cb6f60c515370c6d6",
            "value": " 1622/1622 [01:52&lt;00:00, 14.40it/s]"
          }
        },
        "17bd53288cdb4f47b0c0276c1e0d9f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f56d27747540adb1c4978e299bb532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ac31e0e01344a19ac6f50d1914a1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39c51e39bb434535912a24ebde243e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d121608f774aa98c6fdbd855e0e077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5f736afe63849a8bced171512247572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e09ed874974e8cb6f60c515370c6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85287424de2f49079bccc09dae59334e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cf3c5054f07462e891d82022b9d0ebe",
              "IPY_MODEL_637435dccaf542ca843c08498f2758a5",
              "IPY_MODEL_7c63ae44e0554122b6d5c17a4716d1df"
            ],
            "layout": "IPY_MODEL_f1bc8dd1a78a472d91a870f4bf47ed0f"
          }
        },
        "1cf3c5054f07462e891d82022b9d0ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d03602ae9534bb397faa0d674f20ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_3c93ee1a23b147898c36b840769c4c80",
            "value": " 38%"
          }
        },
        "637435dccaf542ca843c08498f2758a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a46f5520aa4dc681fbac1d51890864",
            "max": 1622,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d84c8a37552c4d6787bd7e9d00ea4a6d",
            "value": 623
          }
        },
        "7c63ae44e0554122b6d5c17a4716d1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b3eb2a4d634e018e032ba8e552c278",
            "placeholder": "​",
            "style": "IPY_MODEL_1583ff4c285a438d9516dbba2f438cb7",
            "value": " 623/1622 [00:43&lt;01:09, 14.43it/s]"
          }
        },
        "f1bc8dd1a78a472d91a870f4bf47ed0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d03602ae9534bb397faa0d674f20ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c93ee1a23b147898c36b840769c4c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14a46f5520aa4dc681fbac1d51890864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84c8a37552c4d6787bd7e9d00ea4a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30b3eb2a4d634e018e032ba8e552c278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1583ff4c285a438d9516dbba2f438cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c26c79f6c0c44f59ec35657d80b9c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cb94f80713741d99a92d67a58875304",
              "IPY_MODEL_21c63e0c11e84cd0bf83a74bbb033b5e",
              "IPY_MODEL_688b7f18063540db94c5f87c9c6421b1"
            ],
            "layout": "IPY_MODEL_c28441ab2d09457b89e0f7082abc1646"
          }
        },
        "3cb94f80713741d99a92d67a58875304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd97b974e2f47b8bd174202405afe31",
            "placeholder": "​",
            "style": "IPY_MODEL_3040d4e40d424796bf560edc303086f2",
            "value": "  4%"
          }
        },
        "21c63e0c11e84cd0bf83a74bbb033b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9854e0270b99413787cf75c805eba384",
            "max": 1622,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7820443076844300b7bf09094d6eeba1",
            "value": 61
          }
        },
        "688b7f18063540db94c5f87c9c6421b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45325119b1154214a40fca24ad9fcfbe",
            "placeholder": "​",
            "style": "IPY_MODEL_317448e1f1194e47bf42e3ae655e783a",
            "value": " 61/1622 [00:04&lt;01:48, 14.42it/s]"
          }
        },
        "c28441ab2d09457b89e0f7082abc1646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbd97b974e2f47b8bd174202405afe31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3040d4e40d424796bf560edc303086f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9854e0270b99413787cf75c805eba384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7820443076844300b7bf09094d6eeba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45325119b1154214a40fca24ad9fcfbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317448e1f1194e47bf42e3ae655e783a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  }
}